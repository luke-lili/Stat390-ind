{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2d08f12d",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Prediction problems: Report\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    code-fold: show\n",
    "    self-contained: true\n",
    "    html-math-method: mathml \n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe6ec7",
   "metadata": {},
   "source": [
    "## Instructions {-}\n",
    "\n",
    "1. This is the template you may use to submit your code and report for the prediction problems on Kaggle.\n",
    "\n",
    "2. You may modify the template if you deem fit, but it should have the information asked below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d691ac",
   "metadata": {},
   "source": [
    "## A.1) Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaaaea5",
   "metadata": {},
   "source": [
    "Mention the data cleaning steps taken to prepare your data for developing the model. This may include imputing missing values, dealing with outliers, combining levels of categorical variable(s), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94664bd",
   "metadata": {},
   "source": [
    "* Put your data cleaning/preparation code with comments here\n",
    "* The code should begin from reading the train data\n",
    "* The code should end when you obtain the data used to develop the model in A.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a6a99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import impute\n",
    "import itertools as it\n",
    "import time as time\n",
    "from sklearn.model_selection import KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# Log transformation of response variable\n",
    "y = np.log(data.y)\n",
    "X = data.drop('y', axis=1)\n",
    "\n",
    "\n",
    "# Drop columns with >5% NaN\n",
    "inst = X.shape[0]\n",
    "nan_col = [col for col in X if (X[col].isna().sum() / inst > 0.05)]\n",
    "X = X.drop(nan_col, axis=1)\n",
    "\n",
    "\n",
    "#Impute NaN values from remaining columns using KNNImputer\n",
    "imputer = impute.KNNImputer(n_neighbors=5)\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1608757",
   "metadata": {},
   "source": [
    "## A.2) Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761fff41",
   "metadata": {},
   "source": [
    "Mention any major insights you obtained from the data, which you used to develop the model. PLease put your code or visualizations here if needed.\n",
    "\n",
    "- Insight 1\n",
    "- Insight 2\n",
    "- ........."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d43d8af",
   "metadata": {},
   "source": [
    "## A.3) Feature selection/reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fc78b0",
   "metadata": {},
   "source": [
    "Mention the steps for feature selection/reduction. PLease put your code or visualizations here if needed.\n",
    "\n",
    "- step 1\n",
    "- step 2\n",
    "- ........."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d382a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1\n",
    "# Delete 0 variance columns\n",
    "X = pd.DataFrame(X)\n",
    "zero_var = []\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "res=[]\n",
    "for col in X:\n",
    "     if len(X[col].unique()) == 1:\n",
    "        res.append(col)\n",
    "        X = X.drop(col, axis=1)\n",
    "\n",
    "print('Columns dropped:', len(res))\n",
    "# 11 columns with only 1 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4497b00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2\n",
    "# Feature Selection - compare feature importances to random columns\n",
    "np.warnings.filterwarnings('ignore')\n",
    "\n",
    "#Set random columns to assist search for non-important columns\n",
    "from numpy import random\n",
    "random.seed(seed=0)\n",
    "for i in range(X.shape[1]):\n",
    "  random = pd.Series(np.random.randn(X.shape[0]))\n",
    "  X[f'random{i}'] = random\n",
    "\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Use RandomForestRegressor to find feature_importances\n",
    "X.columns = X.columns.astype(str)\n",
    "rf = RandomForestRegressor().fit(X,y)\n",
    "\n",
    "imp = rf.feature_importances_\n",
    "importances = pd.DataFrame({'feature':X.columns, 'importance':imp})\n",
    "\n",
    "# Find most important random column\n",
    "random_imp = importances.loc[range(717, 1432), 'importance'].max()\n",
    "\n",
    "# Delete columns from the original set if they are less important than max random importance found above\n",
    "selected_predictors = importances[importances['importance'] > random_imp]['feature'].astype(str).tolist()\n",
    "\n",
    "X = X.loc[:,selected_predictors]\n",
    "#Down to 62 predictors after importance selection\n",
    "\n",
    "# X is our final training dataset with 62 remaining features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd58e2ad",
   "metadata": {},
   "source": [
    "## A.4) Developing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e72c68",
   "metadata": {},
   "source": [
    "Mention the logical sequence of steps taken to obtain the final model. \n",
    "\n",
    "- Model 1\n",
    "- Model 2\n",
    "- ........."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccaac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 1\n",
    "# RandomForest\n",
    "params = {'max_depth':[20, 25, 30],\n",
    "          'max_leaf_nodes':[450, 500, 550],\n",
    "          'bootstrap': [True],\n",
    "         'max_features': [0.7, 0.8, 0.9, 1]}\n",
    "\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=1)\n",
    "\n",
    "rf = GridSearchCV(RandomForestRegressor(random_state=1, n_jobs=-1, bootstrap=True, n_estimators=100), \n",
    "                                      param_grid =params, cv=cv, n_jobs=-1, verbose=1, scoring = 'neg_mean_squared_error')\n",
    "\n",
    "rf.fit(X, y)\n",
    "\n",
    "print('Best Parameters : ',rf.best_params_)\n",
    "\n",
    "# Giving final model\n",
    "tuned_rf = RandomForestRegressor(random_state=1, n_jobs=-1, bootstrap=True, n_estimators=100,\n",
    "                                 max_depth= 25, max_features= 0.8, max_leaf_nodes= 500).fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e55038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 2\n",
    "# XGBoost\n",
    "param_grid = {'max_depth': [4,6,8],\n",
    "              'learning_rate': [0.01, 0.05, 0.1],\n",
    "               'reg_lambda':[0, 1, 10],\n",
    "                'n_estimators':[100, 500, 1000],\n",
    "                'gamma': [0, 10, 100],\n",
    "                'subsample': [0.5, 0.75, 1.0],\n",
    "                'colsample_bytree': [0.5, 0.75, 1.0]}\n",
    "\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=1)\n",
    "optimal_params = RandomizedSearchCV(estimator=xgb.XGBRegressor(random_state=1),                                                       \n",
    "                             param_distributions = param_grid,\n",
    "                             n_iter=100,\n",
    "                             verbose = 1,\n",
    "                             n_jobs=-1,\n",
    "                             cv = cv,\n",
    "                             scoring = 'neg_mean_squared_error')\n",
    "optimal_params.fit(X,y)\n",
    "print(\"Optimal parameter values =\", optimal_params.best_params_)\n",
    "\n",
    "# Giving final model\n",
    "xg = xgb.XGBRegressor(random_state=1, subsample= 0.5, reg_lambda= 1, n_estimators= 500, \n",
    "                       max_depth= 4, learning_rate= 0.05, gamma= 0, colsample_bytree= 1.0).fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811b1aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 3\n",
    "# CatBoost\n",
    "\n",
    "param_grid = {'max_depth': [4,6,8],\n",
    "              'num_leaves': [20, 31, 40],\n",
    "              'learning_rate': [0.01, 0.05, 0.1],\n",
    "               'reg_lambda':[0, 10, 100],\n",
    "                'n_estimators':[100, 500, 1000],\n",
    "                'subsample': [0.5, 0.75, 1.0]}\n",
    "\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=1)\n",
    "optimal_params = RandomizedSearchCV(estimator=CatBoostRegressor(random_state=1, verbose=False),                                                       \n",
    "                             param_distributions = param_grid, n_iter = 100,\n",
    "                             verbose = 1,random_state = 1,\n",
    "                             n_jobs=-1,\n",
    "                             cv = cv)\n",
    "optimal_params.fit(X,y)\n",
    "\n",
    "#Giving Final Model\n",
    "model_cat = CatBoostRegressor(random_state=1, verbose=False, subsample=0.75, reg_lambda=10, num_leaves=31,\n",
    "                              n_estimators=1000, max_depth=4, learning_rate=0.1).fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313b73b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 4 - FINAL MODEL\n",
    "# Ensemble with StackingRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "en = StackingRegressor(estimators = [('cat', model_cat), ('xg', xg), ('rf', tuned_rf)],\n",
    "                     final_estimator=LinearRegression(),                                          \n",
    "                    cv = KFold(n_splits = 5, shuffle = True, random_state=1))\n",
    "en.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c148744c",
   "metadata": {},
   "source": [
    "## A.5) Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ef6e03",
   "metadata": {},
   "source": [
    "Please provide details of the models/approaches you attempted but encountered challenges or unfavorable outcomes. If feasible, kindly explain the reasons behind their ineffectiveness or lack of success. Additionally, highlight the significant challenges or issues you encountered during the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda7b917",
   "metadata": {},
   "source": [
    "## A.6) Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab0af5e",
   "metadata": {},
   "source": [
    "* Do you feel that you gain valuable experience, skills, and/or knowledge? If yes, please explain what they were. If no, please explain.\n",
    "* What are things you liked/disliked about the project and/or work on the project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f993ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22f42714",
   "metadata": {},
   "source": [
    "## Please make sure your github repo has all the code and  ensure that your code is capable of reproducing the outcomes you have submitted. It is important to avoid any form of academic misconduct or cheating by using your peer's submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d78ac51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
