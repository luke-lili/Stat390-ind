{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac514481",
   "metadata": {
    "id": "ac514481"
   },
   "outputs": [],
   "source": [
    "# 303 Tips\n",
    "\n",
    "# Imputing\n",
    "    # KNNImputer from 303-1 notes\n",
    "        # Using same k for all columns is fine \n",
    "        \n",
    "# Check with .unique() to see if columns make sense\n",
    "\n",
    "# Check correlation - Should be able to drop ~200 columns this way\n",
    "\n",
    "# Start with feature importance models (DecisionTree and MARS)\n",
    "    # Stick to the predictors with higher importances - select some subsets\n",
    "    \n",
    "# Start writing tuning code\n",
    "    # RF\n",
    "    # MARS\n",
    "    # AdaBoost\n",
    "    # XGBoost\n",
    "    \n",
    "# SET UP GOOGLE COLLAB\n",
    "\n",
    "# Week 8: Ensembles\n",
    "\n",
    "# Can bag with other models (not tree- model not covered for classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b86b369d",
   "metadata": {
    "id": "b86b369d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import impute\n",
    "import itertools as it\n",
    "import time as time\n",
    "from sklearn.model_selection import KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "#Create cluster dummies\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "# clusters = KMeans(random_state=0, n_clusters = 10)\n",
    "# clusters.fit(data)\n",
    "\n",
    "# pred = clusters.predict(data)\n",
    "# data['Cluster'] = pred\n",
    "# data.Cluster = data.Cluster.astype(str)\n",
    "\n",
    "# Log transformation\n",
    "y = np.log(data.y)\n",
    "X = data.drop('y', axis=1)\n",
    "\n",
    "\n",
    "# Drop columns with >5% NaN\n",
    "inst = X.shape[0]\n",
    "nan_col = [col for col in X if (X[col].isna().sum() / inst > 0.05)]\n",
    "X = X.drop(nan_col, axis=1)\n",
    "\n",
    "\n",
    "#Impute NaN using KNNImputer\n",
    "imputer = impute.KNNImputer(n_neighbors=5)\n",
    "X = imputer.fit_transform(X)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d01093",
   "metadata": {
    "id": "05d01093",
    "outputId": "bd5f6539-154d-478c-9657-173c9ee5891b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>717</th>\n",
       "      <th>718</th>\n",
       "      <th>719</th>\n",
       "      <th>720</th>\n",
       "      <th>721</th>\n",
       "      <th>722</th>\n",
       "      <th>723</th>\n",
       "      <th>724</th>\n",
       "      <th>725</th>\n",
       "      <th>726</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.731729</td>\n",
       "      <td>0.970650</td>\n",
       "      <td>-0.607871</td>\n",
       "      <td>1.646275</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>1.290638</td>\n",
       "      <td>0.292676</td>\n",
       "      <td>-0.579861</td>\n",
       "      <td>-0.612177</td>\n",
       "      <td>-0.278328</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.434068</td>\n",
       "      <td>2.883111</td>\n",
       "      <td>-0.234542</td>\n",
       "      <td>-0.392860</td>\n",
       "      <td>-0.732046</td>\n",
       "      <td>-0.281516</td>\n",
       "      <td>1.289516</td>\n",
       "      <td>-0.279573</td>\n",
       "      <td>-0.229378</td>\n",
       "      <td>-0.840794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.731085</td>\n",
       "      <td>-0.823592</td>\n",
       "      <td>-0.024523</td>\n",
       "      <td>-1.275256</td>\n",
       "      <td>-0.298702</td>\n",
       "      <td>-0.712843</td>\n",
       "      <td>-1.443005</td>\n",
       "      <td>0.958220</td>\n",
       "      <td>-0.101120</td>\n",
       "      <td>0.742470</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.725169</td>\n",
       "      <td>-0.588173</td>\n",
       "      <td>0.721319</td>\n",
       "      <td>-0.266476</td>\n",
       "      <td>-0.908712</td>\n",
       "      <td>1.879752</td>\n",
       "      <td>-0.811894</td>\n",
       "      <td>1.770119</td>\n",
       "      <td>-0.758149</td>\n",
       "      <td>0.732472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.730441</td>\n",
       "      <td>-0.269384</td>\n",
       "      <td>-0.860578</td>\n",
       "      <td>-0.786297</td>\n",
       "      <td>-0.302801</td>\n",
       "      <td>-0.269982</td>\n",
       "      <td>-1.443005</td>\n",
       "      <td>-0.512824</td>\n",
       "      <td>-0.942933</td>\n",
       "      <td>-0.150716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556277</td>\n",
       "      <td>0.226029</td>\n",
       "      <td>-0.215916</td>\n",
       "      <td>-0.392868</td>\n",
       "      <td>0.186620</td>\n",
       "      <td>-0.169499</td>\n",
       "      <td>0.028670</td>\n",
       "      <td>-0.185334</td>\n",
       "      <td>-0.140474</td>\n",
       "      <td>-0.724503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.729797</td>\n",
       "      <td>-0.639873</td>\n",
       "      <td>0.145935</td>\n",
       "      <td>-0.676281</td>\n",
       "      <td>-0.294604</td>\n",
       "      <td>-0.447105</td>\n",
       "      <td>-1.443005</td>\n",
       "      <td>0.219178</td>\n",
       "      <td>-0.021785</td>\n",
       "      <td>-0.282743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775354</td>\n",
       "      <td>0.043078</td>\n",
       "      <td>-0.240469</td>\n",
       "      <td>-0.379623</td>\n",
       "      <td>-0.308046</td>\n",
       "      <td>-0.291399</td>\n",
       "      <td>-0.391612</td>\n",
       "      <td>-0.291352</td>\n",
       "      <td>-0.532588</td>\n",
       "      <td>0.275508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.729153</td>\n",
       "      <td>-0.299226</td>\n",
       "      <td>-0.891836</td>\n",
       "      <td>1.352899</td>\n",
       "      <td>-0.261818</td>\n",
       "      <td>-0.852600</td>\n",
       "      <td>-0.267221</td>\n",
       "      <td>-0.592556</td>\n",
       "      <td>-0.884625</td>\n",
       "      <td>-0.275005</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.103301</td>\n",
       "      <td>-0.844447</td>\n",
       "      <td>-0.236236</td>\n",
       "      <td>-0.392867</td>\n",
       "      <td>-0.802712</td>\n",
       "      <td>-0.261748</td>\n",
       "      <td>-0.391612</td>\n",
       "      <td>-0.273683</td>\n",
       "      <td>0.361564</td>\n",
       "      <td>-0.932165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5375</th>\n",
       "      <td>1.729153</td>\n",
       "      <td>-0.811236</td>\n",
       "      <td>0.872754</td>\n",
       "      <td>0.387205</td>\n",
       "      <td>-0.282309</td>\n",
       "      <td>-1.070487</td>\n",
       "      <td>0.964553</td>\n",
       "      <td>-0.179294</td>\n",
       "      <td>0.701509</td>\n",
       "      <td>-0.288272</td>\n",
       "      <td>...</td>\n",
       "      <td>3.086159</td>\n",
       "      <td>2.417614</td>\n",
       "      <td>-0.240469</td>\n",
       "      <td>-0.392866</td>\n",
       "      <td>-1.014712</td>\n",
       "      <td>-0.297989</td>\n",
       "      <td>-0.811894</td>\n",
       "      <td>-0.291352</td>\n",
       "      <td>-0.668430</td>\n",
       "      <td>0.013262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5376</th>\n",
       "      <td>1.729797</td>\n",
       "      <td>0.893357</td>\n",
       "      <td>0.620776</td>\n",
       "      <td>0.668357</td>\n",
       "      <td>-0.212638</td>\n",
       "      <td>0.061688</td>\n",
       "      <td>0.236687</td>\n",
       "      <td>-0.265555</td>\n",
       "      <td>0.571452</td>\n",
       "      <td>-0.273831</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130962</td>\n",
       "      <td>-0.335720</td>\n",
       "      <td>-0.237929</td>\n",
       "      <td>-0.392870</td>\n",
       "      <td>-1.156045</td>\n",
       "      <td>-0.278221</td>\n",
       "      <td>0.869234</td>\n",
       "      <td>-0.267793</td>\n",
       "      <td>0.926481</td>\n",
       "      <td>-0.174443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5377</th>\n",
       "      <td>1.730441</td>\n",
       "      <td>-0.368885</td>\n",
       "      <td>0.746220</td>\n",
       "      <td>-0.065082</td>\n",
       "      <td>-0.257719</td>\n",
       "      <td>0.472798</td>\n",
       "      <td>0.516635</td>\n",
       "      <td>-0.374215</td>\n",
       "      <td>0.252689</td>\n",
       "      <td>-0.222228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.884225</td>\n",
       "      <td>-0.557841</td>\n",
       "      <td>-0.192210</td>\n",
       "      <td>-0.392871</td>\n",
       "      <td>0.681287</td>\n",
       "      <td>-0.153026</td>\n",
       "      <td>-0.811894</td>\n",
       "      <td>-0.126435</td>\n",
       "      <td>-0.544819</td>\n",
       "      <td>-0.128596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td>1.731085</td>\n",
       "      <td>-0.052157</td>\n",
       "      <td>-0.713373</td>\n",
       "      <td>1.695171</td>\n",
       "      <td>-0.257719</td>\n",
       "      <td>-0.892355</td>\n",
       "      <td>0.180697</td>\n",
       "      <td>-0.595953</td>\n",
       "      <td>-0.742034</td>\n",
       "      <td>-0.278881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808365</td>\n",
       "      <td>-0.218928</td>\n",
       "      <td>-0.239622</td>\n",
       "      <td>-0.385486</td>\n",
       "      <td>-0.166713</td>\n",
       "      <td>-0.288105</td>\n",
       "      <td>0.028670</td>\n",
       "      <td>-0.279573</td>\n",
       "      <td>1.000389</td>\n",
       "      <td>-0.909079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5379</th>\n",
       "      <td>1.731729</td>\n",
       "      <td>-0.810772</td>\n",
       "      <td>-0.913108</td>\n",
       "      <td>-0.321786</td>\n",
       "      <td>-0.310997</td>\n",
       "      <td>-0.889237</td>\n",
       "      <td>-1.443005</td>\n",
       "      <td>-0.552803</td>\n",
       "      <td>-0.916928</td>\n",
       "      <td>-0.291209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.442238</td>\n",
       "      <td>0.231522</td>\n",
       "      <td>-0.240469</td>\n",
       "      <td>-0.174344</td>\n",
       "      <td>0.610620</td>\n",
       "      <td>-0.297989</td>\n",
       "      <td>-0.811894</td>\n",
       "      <td>-0.291352</td>\n",
       "      <td>-0.723915</td>\n",
       "      <td>-0.789121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5380 rows Ã— 727 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0    -1.731729  0.970650 -0.607871  1.646275  0.000475  1.290638  0.292676   \n",
       "1    -1.731085 -0.823592 -0.024523 -1.275256 -0.298702 -0.712843 -1.443005   \n",
       "2    -1.730441 -0.269384 -0.860578 -0.786297 -0.302801 -0.269982 -1.443005   \n",
       "3    -1.729797 -0.639873  0.145935 -0.676281 -0.294604 -0.447105 -1.443005   \n",
       "4    -1.729153 -0.299226 -0.891836  1.352899 -0.261818 -0.852600 -0.267221   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5375  1.729153 -0.811236  0.872754  0.387205 -0.282309 -1.070487  0.964553   \n",
       "5376  1.729797  0.893357  0.620776  0.668357 -0.212638  0.061688  0.236687   \n",
       "5377  1.730441 -0.368885  0.746220 -0.065082 -0.257719  0.472798  0.516635   \n",
       "5378  1.731085 -0.052157 -0.713373  1.695171 -0.257719 -0.892355  0.180697   \n",
       "5379  1.731729 -0.810772 -0.913108 -0.321786 -0.310997 -0.889237 -1.443005   \n",
       "\n",
       "           7         8         9    ...       717       718       719  \\\n",
       "0    -0.579861 -0.612177 -0.278328  ... -0.434068  2.883111 -0.234542   \n",
       "1     0.958220 -0.101120  0.742470  ... -0.725169 -0.588173  0.721319   \n",
       "2    -0.512824 -0.942933 -0.150716  ...  0.556277  0.226029 -0.215916   \n",
       "3     0.219178 -0.021785 -0.282743  ...  0.775354  0.043078 -0.240469   \n",
       "4    -0.592556 -0.884625 -0.275005  ... -1.103301 -0.844447 -0.236236   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5375 -0.179294  0.701509 -0.288272  ...  3.086159  2.417614 -0.240469   \n",
       "5376 -0.265555  0.571452 -0.273831  ... -0.130962 -0.335720 -0.237929   \n",
       "5377 -0.374215  0.252689 -0.222228  ... -0.884225 -0.557841 -0.192210   \n",
       "5378 -0.595953 -0.742034 -0.278881  ...  0.808365 -0.218928 -0.239622   \n",
       "5379 -0.552803 -0.916928 -0.291209  ...  0.442238  0.231522 -0.240469   \n",
       "\n",
       "           720       721       722       723       724       725       726  \n",
       "0    -0.392860 -0.732046 -0.281516  1.289516 -0.279573 -0.229378 -0.840794  \n",
       "1    -0.266476 -0.908712  1.879752 -0.811894  1.770119 -0.758149  0.732472  \n",
       "2    -0.392868  0.186620 -0.169499  0.028670 -0.185334 -0.140474 -0.724503  \n",
       "3    -0.379623 -0.308046 -0.291399 -0.391612 -0.291352 -0.532588  0.275508  \n",
       "4    -0.392867 -0.802712 -0.261748 -0.391612 -0.273683  0.361564 -0.932165  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5375 -0.392866 -1.014712 -0.297989 -0.811894 -0.291352 -0.668430  0.013262  \n",
       "5376 -0.392870 -1.156045 -0.278221  0.869234 -0.267793  0.926481 -0.174443  \n",
       "5377 -0.392871  0.681287 -0.153026 -0.811894 -0.126435 -0.544819 -0.128596  \n",
       "5378 -0.385486 -0.166713 -0.288105  0.028670 -0.279573  1.000389 -0.909079  \n",
       "5379 -0.174344  0.610620 -0.297989 -0.811894 -0.291352 -0.723915 -0.789121  \n",
       "\n",
       "[5380 rows x 727 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47fadc0",
   "metadata": {
    "id": "f47fadc0"
   },
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce7fcef",
   "metadata": {
    "id": "1ce7fcef",
    "outputId": "3bd8b1e6-1672-4b28-8557-c8459b814997"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29911\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data.isna().sum())\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('# NaN')\n",
    "print(data.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f59b2c",
   "metadata": {
    "id": "42f59b2c"
   },
   "source": [
    "## Response Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e12867",
   "metadata": {
    "id": "d4e12867",
    "outputId": "e43f29cd-aae0-4e60-8226-0408a2299100"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5380.000000\n",
       "mean        8.630297\n",
       "std        12.016238\n",
       "min         1.000000\n",
       "25%         2.000000\n",
       "50%         5.000000\n",
       "75%        10.000000\n",
       "max       100.000000\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2594a7a9",
   "metadata": {
    "id": "2594a7a9",
    "outputId": "e1df927f-6cde-4fc8-f277-08878dddf36b",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcb3bb6b6a0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "sns.boxplot(data.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e161a7",
   "metadata": {
    "id": "71e161a7"
   },
   "source": [
    "## Column Value Inspection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f55478b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5f55478b",
    "outputId": "024936d5-772a-4edb-d534-1aa22edfde04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5380, 727)\n",
      "Columns dropped: 11\n",
      "(5380, 716)\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame(X)\n",
    "zero_var = []\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "res=[]\n",
    "for col in X:\n",
    "     if len(X[col].unique()) == 1:\n",
    "        res.append(col)\n",
    "        X = X.drop(col, axis=1)\n",
    "\n",
    "print('Columns dropped:', len(res))\n",
    "# 11 columns with only 1 value\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e576df6",
   "metadata": {
    "id": "1e576df6"
   },
   "outputs": [],
   "source": [
    "# Column Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbcfe9f",
   "metadata": {
    "id": "5dbcfe9f",
    "outputId": "d772b7c0-880d-45d6-8c9a-5adda699bd68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "Int64Index([ 68,  80, 110, 115, 118, 134, 164, 165, 173, 198, 200, 203, 206,\n",
      "            207, 217, 223, 230, 266, 267, 268, 274, 284, 300, 323, 324, 334,\n",
      "            335, 355, 360, 364, 365, 367, 380, 385, 399, 414, 419, 421, 422,\n",
      "            430, 435, 438, 444, 449, 450, 458, 461, 468, 470, 471, 472, 474,\n",
      "            516, 521, 523, 524, 527, 542, 550, 568, 569, 582, 587, 589, 592,\n",
      "            595, 602, 603, 623, 630, 644, 648, 651, 655, 659, 671, 680, 689,\n",
      "            706, 710, 716, 722, 723, 724],\n",
      "           dtype='int64')\n",
      "(5380, 632)\n"
     ]
    }
   ],
   "source": [
    "## Not working right now - is removing both\n",
    "\n",
    "# Duplicated columns\n",
    "duplicated_cols = X.columns[X.transpose().duplicated(keep='first')]\n",
    "print(len(duplicated_cols))\n",
    "print(duplicated_cols)\n",
    "\n",
    "# Drop the duplicated columns\n",
    "X.drop(duplicated_cols, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d27fbd",
   "metadata": {
    "id": "c2d27fbd"
   },
   "outputs": [],
   "source": [
    "X.T.drop_duplicates(keep='first').T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526fb6ac",
   "metadata": {
    "id": "526fb6ac"
   },
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c34628",
   "metadata": {
    "id": "05c34628",
    "outputId": "0c2311a8-9b63-4ac9-b894-3a8a9a4b99bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y       1.000000\n",
       "x146    0.378696\n",
       "x102    0.378436\n",
       "x014    0.364737\n",
       "x581    0.346539\n",
       "x619    0.344101\n",
       "x687    0.343842\n",
       "x696    0.329630\n",
       "x651    0.329630\n",
       "x755    0.324916\n",
       "x756    0.312253\n",
       "x569    0.311497\n",
       "x543    0.308728\n",
       "x749    0.296195\n",
       "x591    0.293075\n",
       "x427    0.293073\n",
       "x561    0.279915\n",
       "x572    0.273481\n",
       "x670    0.272551\n",
       "x239    0.271268\n",
       "dtype: float64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correlation Analysis\n",
    "data.corrwith(data.y).sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab85637",
   "metadata": {
    "id": "cab85637",
    "outputId": "09306375-8fe1-4ecd-a613-9ae83077bb39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7438.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perfect_corr = (abs(X.corr()) > 0.9)\n",
    "(perfect_corr.sum().sum() - 755) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "448dca3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "448dca3a",
    "outputId": "10be86d0-f414-46db-8155-62c7305706d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed Columns {8, 10, 11, 12, 21, 29, 30, 33, 34, 37, 38, 39, 40, 42, 44, 45, 50, 52, 53, 54, 55, 56, 57, 61, 62, 63, 64, 66, 68, 70, 75, 77, 79, 80, 83, 84, 86, 89, 90, 92, 94, 96, 97, 99, 101, 102, 103, 104, 107, 108, 110, 111, 113, 115, 117, 118, 120, 121, 124, 125, 128, 131, 133, 134, 135, 138, 139, 140, 141, 142, 143, 145, 146, 149, 150, 151, 152, 153, 154, 155, 156, 158, 160, 162, 164, 165, 166, 168, 169, 170, 173, 175, 176, 177, 178, 181, 182, 183, 186, 187, 188, 190, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 211, 212, 213, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 243, 244, 246, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 265, 266, 267, 268, 269, 270, 272, 273, 274, 277, 278, 279, 280, 281, 282, 283, 284, 286, 287, 288, 290, 291, 292, 293, 295, 297, 299, 300, 301, 302, 304, 305, 307, 308, 310, 311, 312, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 345, 346, 349, 350, 351, 352, 353, 354, 355, 356, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 370, 373, 374, 376, 377, 379, 380, 381, 383, 385, 386, 389, 390, 391, 392, 393, 395, 396, 399, 402, 403, 404, 405, 406, 407, 408, 410, 411, 412, 413, 414, 416, 417, 418, 419, 420, 421, 422, 425, 426, 427, 428, 430, 431, 432, 435, 438, 439, 440, 442, 443, 444, 449, 450, 451, 453, 454, 455, 456, 457, 458, 459, 460, 461, 463, 464, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 478, 480, 482, 483, 484, 485, 486, 488, 489, 491, 493, 495, 498, 499, 500, 501, 503, 506, 507, 508, 509, 511, 512, 513, 514, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 530, 531, 533, 534, 535, 536, 538, 539, 540, 541, 542, 543, 545, 546, 547, 548, 549, 550, 551, 552, 554, 555, 556, 557, 559, 562, 563, 564, 566, 567, 568, 569, 572, 573, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 587, 588, 589, 590, 591, 592, 593, 595, 596, 598, 599, 601, 602, 603, 604, 605, 607, 608, 609, 610, 611, 612, 614, 615, 617, 618, 619, 620, 622, 623, 624, 625, 626, 628, 629, 630, 633, 634, 635, 636, 637, 638, 639, 640, 641, 644, 645, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 662, 663, 664, 665, 666, 667, 670, 671, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 685, 686, 687, 688, 689, 690, 691, 693, 695, 696, 697, 699, 700, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726}\n"
     ]
    }
   ],
   "source": [
    "# Losing variation here?\n",
    "def remove_collinear_features(x, threshold):\n",
    "    # Calculate the correlation matrix\n",
    "    corr_matrix = x.corr()\n",
    "    iters = range(len(corr_matrix.columns) - 1)\n",
    "    drop_cols = []\n",
    "\n",
    "    # Iterate through the correlation matrix and compare correlations\n",
    "    for i in iters:\n",
    "        for j in range(i+1):\n",
    "            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n",
    "            col = item.columns\n",
    "            row = item.index\n",
    "            val = abs(item.values)\n",
    "\n",
    "            # If correlation exceeds the threshold\n",
    "            if val >= threshold:\n",
    "                # Print the correlated features and the correlation value\n",
    "                #print(col.values[0], \"|\", row.values[0], \"|\", round(val[0][0], 2))\n",
    "                drop_cols.append(col.values[0])\n",
    "\n",
    "    # Drop one of each pair of correlated columns\n",
    "    drops = set(drop_cols)\n",
    "    x = x.drop(columns=drops)\n",
    "    print('Removed Columns {}'.format(drops))\n",
    "    return x, drops\n",
    "\n",
    "X, drops = remove_collinear_features(X, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff30b1ca",
   "metadata": {
    "id": "ff30b1ca",
    "outputId": "dd83acd9-ec9a-4b8a-bb28-a409c0a72a8b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>9</th>\n",
       "      <th>13</th>\n",
       "      <th>...</th>\n",
       "      <th>646</th>\n",
       "      <th>661</th>\n",
       "      <th>668</th>\n",
       "      <th>672</th>\n",
       "      <th>684</th>\n",
       "      <th>692</th>\n",
       "      <th>694</th>\n",
       "      <th>698</th>\n",
       "      <th>701</th>\n",
       "      <th>712</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.731729</td>\n",
       "      <td>0.970650</td>\n",
       "      <td>-0.607871</td>\n",
       "      <td>1.646275</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>1.290638</td>\n",
       "      <td>0.292676</td>\n",
       "      <td>-0.579861</td>\n",
       "      <td>-0.278328</td>\n",
       "      <td>-1.783015</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.533122</td>\n",
       "      <td>0.449750</td>\n",
       "      <td>-0.470062</td>\n",
       "      <td>0.140353</td>\n",
       "      <td>-0.274980</td>\n",
       "      <td>-0.426247</td>\n",
       "      <td>-0.108640</td>\n",
       "      <td>-1.405697</td>\n",
       "      <td>0.080381</td>\n",
       "      <td>0.594887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.731085</td>\n",
       "      <td>-0.823592</td>\n",
       "      <td>-0.024523</td>\n",
       "      <td>-1.275256</td>\n",
       "      <td>-0.298702</td>\n",
       "      <td>-0.712843</td>\n",
       "      <td>-1.443005</td>\n",
       "      <td>0.958220</td>\n",
       "      <td>0.742470</td>\n",
       "      <td>0.212986</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169251</td>\n",
       "      <td>-0.866449</td>\n",
       "      <td>-1.672698</td>\n",
       "      <td>-2.138000</td>\n",
       "      <td>0.713741</td>\n",
       "      <td>-0.127829</td>\n",
       "      <td>-0.108640</td>\n",
       "      <td>0.133983</td>\n",
       "      <td>-2.404986</td>\n",
       "      <td>0.594887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.730441</td>\n",
       "      <td>-0.269384</td>\n",
       "      <td>-0.860578</td>\n",
       "      <td>-0.786297</td>\n",
       "      <td>-0.302801</td>\n",
       "      <td>-0.269982</td>\n",
       "      <td>-1.443005</td>\n",
       "      <td>-0.512824</td>\n",
       "      <td>-0.150716</td>\n",
       "      <td>0.087927</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.645082</td>\n",
       "      <td>0.233639</td>\n",
       "      <td>-0.620089</td>\n",
       "      <td>0.013777</td>\n",
       "      <td>0.034913</td>\n",
       "      <td>-0.426247</td>\n",
       "      <td>-1.193997</td>\n",
       "      <td>-0.122631</td>\n",
       "      <td>0.123936</td>\n",
       "      <td>-0.328871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.729797</td>\n",
       "      <td>-0.639873</td>\n",
       "      <td>0.145935</td>\n",
       "      <td>-0.676281</td>\n",
       "      <td>-0.294604</td>\n",
       "      <td>-0.447105</td>\n",
       "      <td>-1.443005</td>\n",
       "      <td>0.219178</td>\n",
       "      <td>-0.282743</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.393171</td>\n",
       "      <td>0.679689</td>\n",
       "      <td>-1.229876</td>\n",
       "      <td>-0.703482</td>\n",
       "      <td>-0.352076</td>\n",
       "      <td>-0.426247</td>\n",
       "      <td>-0.182223</td>\n",
       "      <td>-0.379244</td>\n",
       "      <td>0.071829</td>\n",
       "      <td>0.594887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.729153</td>\n",
       "      <td>-0.299226</td>\n",
       "      <td>-0.891836</td>\n",
       "      <td>1.352899</td>\n",
       "      <td>-0.261818</td>\n",
       "      <td>-0.852600</td>\n",
       "      <td>-0.267221</td>\n",
       "      <td>-0.592556</td>\n",
       "      <td>-0.275005</td>\n",
       "      <td>0.189538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.449151</td>\n",
       "      <td>0.444824</td>\n",
       "      <td>0.110687</td>\n",
       "      <td>0.541174</td>\n",
       "      <td>-0.278549</td>\n",
       "      <td>2.557930</td>\n",
       "      <td>-0.329390</td>\n",
       "      <td>2.186889</td>\n",
       "      <td>0.200618</td>\n",
       "      <td>0.264974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5375</th>\n",
       "      <td>1.729153</td>\n",
       "      <td>-0.811236</td>\n",
       "      <td>0.872754</td>\n",
       "      <td>0.387205</td>\n",
       "      <td>-0.282309</td>\n",
       "      <td>-1.070487</td>\n",
       "      <td>0.964553</td>\n",
       "      <td>-0.179294</td>\n",
       "      <td>-0.288272</td>\n",
       "      <td>-0.568636</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.337191</td>\n",
       "      <td>-1.955216</td>\n",
       "      <td>-1.026614</td>\n",
       "      <td>0.077065</td>\n",
       "      <td>-0.380381</td>\n",
       "      <td>-0.426247</td>\n",
       "      <td>0.351257</td>\n",
       "      <td>-0.122631</td>\n",
       "      <td>-0.142698</td>\n",
       "      <td>0.133008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5376</th>\n",
       "      <td>1.729797</td>\n",
       "      <td>0.893357</td>\n",
       "      <td>0.620776</td>\n",
       "      <td>0.668357</td>\n",
       "      <td>-0.212638</td>\n",
       "      <td>0.061688</td>\n",
       "      <td>0.236687</td>\n",
       "      <td>-0.265555</td>\n",
       "      <td>-0.273831</td>\n",
       "      <td>0.356805</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.365181</td>\n",
       "      <td>-1.526738</td>\n",
       "      <td>-0.966119</td>\n",
       "      <td>0.625557</td>\n",
       "      <td>-0.315750</td>\n",
       "      <td>-0.426247</td>\n",
       "      <td>0.516820</td>\n",
       "      <td>-0.892470</td>\n",
       "      <td>0.038277</td>\n",
       "      <td>0.330956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5377</th>\n",
       "      <td>1.730441</td>\n",
       "      <td>-0.368885</td>\n",
       "      <td>0.746220</td>\n",
       "      <td>-0.065082</td>\n",
       "      <td>-0.257719</td>\n",
       "      <td>0.472798</td>\n",
       "      <td>0.516635</td>\n",
       "      <td>-0.374215</td>\n",
       "      <td>-0.222228</td>\n",
       "      <td>0.209860</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.673072</td>\n",
       "      <td>0.746252</td>\n",
       "      <td>1.327842</td>\n",
       "      <td>0.393503</td>\n",
       "      <td>-0.271993</td>\n",
       "      <td>-0.426247</td>\n",
       "      <td>-0.844475</td>\n",
       "      <td>0.133983</td>\n",
       "      <td>0.041281</td>\n",
       "      <td>0.264974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td>1.731085</td>\n",
       "      <td>-0.052157</td>\n",
       "      <td>-0.713373</td>\n",
       "      <td>1.695171</td>\n",
       "      <td>-0.257719</td>\n",
       "      <td>-0.892355</td>\n",
       "      <td>0.180697</td>\n",
       "      <td>-0.595953</td>\n",
       "      <td>-0.278881</td>\n",
       "      <td>0.552210</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.505132</td>\n",
       "      <td>-1.357043</td>\n",
       "      <td>-0.421666</td>\n",
       "      <td>0.773228</td>\n",
       "      <td>-0.310071</td>\n",
       "      <td>-0.426247</td>\n",
       "      <td>-0.586933</td>\n",
       "      <td>-1.405697</td>\n",
       "      <td>0.028832</td>\n",
       "      <td>-0.130923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5379</th>\n",
       "      <td>1.731729</td>\n",
       "      <td>-0.810772</td>\n",
       "      <td>-0.913108</td>\n",
       "      <td>-0.321786</td>\n",
       "      <td>-0.310997</td>\n",
       "      <td>-0.889237</td>\n",
       "      <td>-1.443005</td>\n",
       "      <td>-0.552803</td>\n",
       "      <td>-0.291209</td>\n",
       "      <td>-0.334149</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113270</td>\n",
       "      <td>-1.711360</td>\n",
       "      <td>0.292172</td>\n",
       "      <td>-0.273126</td>\n",
       "      <td>-0.380381</td>\n",
       "      <td>-0.426247</td>\n",
       "      <td>-0.108640</td>\n",
       "      <td>-1.405697</td>\n",
       "      <td>-0.264576</td>\n",
       "      <td>-2.704251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5380 rows Ã— 191 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0    -1.731729  0.970650 -0.607871  1.646275  0.000475  1.290638  0.292676   \n",
       "1    -1.731085 -0.823592 -0.024523 -1.275256 -0.298702 -0.712843 -1.443005   \n",
       "2    -1.730441 -0.269384 -0.860578 -0.786297 -0.302801 -0.269982 -1.443005   \n",
       "3    -1.729797 -0.639873  0.145935 -0.676281 -0.294604 -0.447105 -1.443005   \n",
       "4    -1.729153 -0.299226 -0.891836  1.352899 -0.261818 -0.852600 -0.267221   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5375  1.729153 -0.811236  0.872754  0.387205 -0.282309 -1.070487  0.964553   \n",
       "5376  1.729797  0.893357  0.620776  0.668357 -0.212638  0.061688  0.236687   \n",
       "5377  1.730441 -0.368885  0.746220 -0.065082 -0.257719  0.472798  0.516635   \n",
       "5378  1.731085 -0.052157 -0.713373  1.695171 -0.257719 -0.892355  0.180697   \n",
       "5379  1.731729 -0.810772 -0.913108 -0.321786 -0.310997 -0.889237 -1.443005   \n",
       "\n",
       "           7         9         13   ...       646       661       668  \\\n",
       "0    -0.579861 -0.278328 -1.783015  ... -0.533122  0.449750 -0.470062   \n",
       "1     0.958220  0.742470  0.212986  ... -0.169251 -0.866449 -1.672698   \n",
       "2    -0.512824 -0.150716  0.087927  ... -0.645082  0.233639 -0.620089   \n",
       "3     0.219178 -0.282743  0.063436  ... -0.393171  0.679689 -1.229876   \n",
       "4    -0.592556 -0.275005  0.189538  ... -0.449151  0.444824  0.110687   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5375 -0.179294 -0.288272 -0.568636  ... -0.337191 -1.955216 -1.026614   \n",
       "5376 -0.265555 -0.273831  0.356805  ... -0.365181 -1.526738 -0.966119   \n",
       "5377 -0.374215 -0.222228  0.209860  ... -0.673072  0.746252  1.327842   \n",
       "5378 -0.595953 -0.278881  0.552210  ... -0.505132 -1.357043 -0.421666   \n",
       "5379 -0.552803 -0.291209 -0.334149  ... -0.113270 -1.711360  0.292172   \n",
       "\n",
       "           672       684       692       694       698       701       712  \n",
       "0     0.140353 -0.274980 -0.426247 -0.108640 -1.405697  0.080381  0.594887  \n",
       "1    -2.138000  0.713741 -0.127829 -0.108640  0.133983 -2.404986  0.594887  \n",
       "2     0.013777  0.034913 -0.426247 -1.193997 -0.122631  0.123936 -0.328871  \n",
       "3    -0.703482 -0.352076 -0.426247 -0.182223 -0.379244  0.071829  0.594887  \n",
       "4     0.541174 -0.278549  2.557930 -0.329390  2.186889  0.200618  0.264974  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5375  0.077065 -0.380381 -0.426247  0.351257 -0.122631 -0.142698  0.133008  \n",
       "5376  0.625557 -0.315750 -0.426247  0.516820 -0.892470  0.038277  0.330956  \n",
       "5377  0.393503 -0.271993 -0.426247 -0.844475  0.133983  0.041281  0.264974  \n",
       "5378  0.773228 -0.310071 -0.426247 -0.586933 -1.405697  0.028832 -0.130923  \n",
       "5379 -0.273126 -0.380381 -0.426247 -0.108640 -1.405697 -0.264576 -2.704251  \n",
       "\n",
       "[5380 rows x 191 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08da1a7f",
   "metadata": {
    "id": "08da1a7f"
   },
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3153846",
   "metadata": {
    "id": "e3153846"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7cbd7089",
   "metadata": {
    "id": "7cbd7089"
   },
   "source": [
    "## PCA Dimension Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8b44fc",
   "metadata": {
    "id": "8c8b44fc"
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame(columns=['Percent', 'Dim'])\n",
    "for n in np.arange(0.95, 0, -0.05):\n",
    "    pca = PCA(n_components = n, svd_solver = 'full')\n",
    "    pca_data = pca.fit_transform(X)\n",
    "\n",
    "    dim = pca_data.shape[1]\n",
    "    res = res.append(pd.DataFrame({'Percent':n, 'Dim':dim}, index=[0]))\n",
    "    \n",
    "res = res.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfbd945",
   "metadata": {
    "id": "5dfbd945",
    "outputId": "56ebfdd8-94a8-4d3f-f2a3-cac53754d69b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Dimensions')"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(res.Percent, res.Dim)\n",
    "plt.xlabel('Percent Variation')\n",
    "plt.ylabel('Dimensions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3760d449",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3760d449",
    "outputId": "4a2ed389-9851-407b-9b5a-fc2754ac0dcb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5380, 97)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components = 0.9, svd_solver = 'full')\n",
    "pca_data = pca.fit_transform(X)\n",
    "\n",
    "dim = pca_data.shape[1]\n",
    "X = pca_data\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5681f3",
   "metadata": {
    "id": "ae5681f3"
   },
   "source": [
    "## DBSCAN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e33a35",
   "metadata": {
    "id": "62e33a35",
    "outputId": "ce189ab9-dc5c-41e2-c689-9a3f84c176cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DBSCAN clustering\n",
    "db = DBSCAN(eps=50, min_samples=2)\n",
    "db.fit_predict(X)\n",
    "db.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6678286f",
   "metadata": {
    "id": "6678286f",
    "outputId": "7caecfda-a324-40b0-9fe5-6a1b252a1bed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.781835</td>\n",
       "      <td>-10.550425</td>\n",
       "      <td>-1.389333</td>\n",
       "      <td>11.412608</td>\n",
       "      <td>-3.948730</td>\n",
       "      <td>0.184892</td>\n",
       "      <td>2.079231</td>\n",
       "      <td>-3.931734</td>\n",
       "      <td>0.882259</td>\n",
       "      <td>-0.292678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308264</td>\n",
       "      <td>-0.216018</td>\n",
       "      <td>0.046164</td>\n",
       "      <td>-0.064197</td>\n",
       "      <td>-0.052060</td>\n",
       "      <td>1.383777</td>\n",
       "      <td>0.782678</td>\n",
       "      <td>-0.844220</td>\n",
       "      <td>0.596582</td>\n",
       "      <td>-0.697189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-13.703336</td>\n",
       "      <td>0.700874</td>\n",
       "      <td>1.600031</td>\n",
       "      <td>-2.889409</td>\n",
       "      <td>5.369754</td>\n",
       "      <td>7.947973</td>\n",
       "      <td>0.806274</td>\n",
       "      <td>-2.257151</td>\n",
       "      <td>-1.315446</td>\n",
       "      <td>-2.476533</td>\n",
       "      <td>...</td>\n",
       "      <td>4.484327</td>\n",
       "      <td>-1.754804</td>\n",
       "      <td>-1.805732</td>\n",
       "      <td>-0.870102</td>\n",
       "      <td>-0.602934</td>\n",
       "      <td>-0.781125</td>\n",
       "      <td>4.719386</td>\n",
       "      <td>0.023884</td>\n",
       "      <td>0.813408</td>\n",
       "      <td>1.291091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.462429</td>\n",
       "      <td>-9.296243</td>\n",
       "      <td>1.776078</td>\n",
       "      <td>-2.945392</td>\n",
       "      <td>0.591712</td>\n",
       "      <td>2.946641</td>\n",
       "      <td>-2.010665</td>\n",
       "      <td>4.974082</td>\n",
       "      <td>-1.538967</td>\n",
       "      <td>-2.179788</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.615271</td>\n",
       "      <td>0.152359</td>\n",
       "      <td>0.110833</td>\n",
       "      <td>0.351977</td>\n",
       "      <td>-0.917847</td>\n",
       "      <td>-0.105817</td>\n",
       "      <td>0.647814</td>\n",
       "      <td>0.202271</td>\n",
       "      <td>-0.120393</td>\n",
       "      <td>0.264436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.334259</td>\n",
       "      <td>-4.577142</td>\n",
       "      <td>4.333773</td>\n",
       "      <td>-3.305378</td>\n",
       "      <td>-1.062078</td>\n",
       "      <td>-0.305052</td>\n",
       "      <td>2.860698</td>\n",
       "      <td>0.256052</td>\n",
       "      <td>0.939384</td>\n",
       "      <td>-2.921690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217654</td>\n",
       "      <td>0.908828</td>\n",
       "      <td>-0.440344</td>\n",
       "      <td>-0.598833</td>\n",
       "      <td>0.288496</td>\n",
       "      <td>-1.316715</td>\n",
       "      <td>1.020567</td>\n",
       "      <td>1.088397</td>\n",
       "      <td>0.094585</td>\n",
       "      <td>-0.904364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.380139</td>\n",
       "      <td>-4.903977</td>\n",
       "      <td>-0.674055</td>\n",
       "      <td>-5.754902</td>\n",
       "      <td>4.575190</td>\n",
       "      <td>0.417406</td>\n",
       "      <td>-3.198909</td>\n",
       "      <td>2.866728</td>\n",
       "      <td>-8.067099</td>\n",
       "      <td>3.159759</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.211351</td>\n",
       "      <td>2.108729</td>\n",
       "      <td>-0.738576</td>\n",
       "      <td>1.180693</td>\n",
       "      <td>-0.598859</td>\n",
       "      <td>1.186879</td>\n",
       "      <td>1.795002</td>\n",
       "      <td>-0.179036</td>\n",
       "      <td>0.260185</td>\n",
       "      <td>-1.661345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5375</th>\n",
       "      <td>-1.301857</td>\n",
       "      <td>-12.441267</td>\n",
       "      <td>6.887888</td>\n",
       "      <td>0.963782</td>\n",
       "      <td>-8.986152</td>\n",
       "      <td>2.616209</td>\n",
       "      <td>0.904449</td>\n",
       "      <td>3.240487</td>\n",
       "      <td>1.895097</td>\n",
       "      <td>-1.648082</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.035582</td>\n",
       "      <td>-0.785636</td>\n",
       "      <td>0.561686</td>\n",
       "      <td>-0.522764</td>\n",
       "      <td>0.655445</td>\n",
       "      <td>-0.246902</td>\n",
       "      <td>-0.684642</td>\n",
       "      <td>1.358684</td>\n",
       "      <td>-0.723941</td>\n",
       "      <td>1.488930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5376</th>\n",
       "      <td>11.180929</td>\n",
       "      <td>-0.771640</td>\n",
       "      <td>6.697330</td>\n",
       "      <td>-3.333841</td>\n",
       "      <td>-0.178603</td>\n",
       "      <td>0.563499</td>\n",
       "      <td>-1.984782</td>\n",
       "      <td>0.664532</td>\n",
       "      <td>0.099215</td>\n",
       "      <td>-1.652088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414626</td>\n",
       "      <td>-0.474428</td>\n",
       "      <td>-0.698460</td>\n",
       "      <td>-0.351142</td>\n",
       "      <td>-0.151871</td>\n",
       "      <td>0.043417</td>\n",
       "      <td>0.541379</td>\n",
       "      <td>-0.663330</td>\n",
       "      <td>-0.531068</td>\n",
       "      <td>-0.296129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5377</th>\n",
       "      <td>-0.348706</td>\n",
       "      <td>-8.609050</td>\n",
       "      <td>6.310708</td>\n",
       "      <td>0.992539</td>\n",
       "      <td>5.211123</td>\n",
       "      <td>-2.689503</td>\n",
       "      <td>-4.325625</td>\n",
       "      <td>0.290483</td>\n",
       "      <td>-1.422859</td>\n",
       "      <td>0.870810</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.770339</td>\n",
       "      <td>-0.250563</td>\n",
       "      <td>0.919247</td>\n",
       "      <td>-0.606629</td>\n",
       "      <td>1.581885</td>\n",
       "      <td>-0.162867</td>\n",
       "      <td>-0.270071</td>\n",
       "      <td>0.274389</td>\n",
       "      <td>0.385588</td>\n",
       "      <td>0.320263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td>13.905367</td>\n",
       "      <td>-2.265077</td>\n",
       "      <td>-1.641486</td>\n",
       "      <td>-8.381800</td>\n",
       "      <td>-4.549641</td>\n",
       "      <td>1.352257</td>\n",
       "      <td>-3.287034</td>\n",
       "      <td>-0.714738</td>\n",
       "      <td>2.623186</td>\n",
       "      <td>2.368429</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132435</td>\n",
       "      <td>1.109315</td>\n",
       "      <td>1.145495</td>\n",
       "      <td>1.482847</td>\n",
       "      <td>-0.486009</td>\n",
       "      <td>-0.134528</td>\n",
       "      <td>-0.146896</td>\n",
       "      <td>0.391888</td>\n",
       "      <td>1.089321</td>\n",
       "      <td>-0.227498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5379</th>\n",
       "      <td>-5.939059</td>\n",
       "      <td>-9.050252</td>\n",
       "      <td>-6.440438</td>\n",
       "      <td>-5.858641</td>\n",
       "      <td>-7.531106</td>\n",
       "      <td>0.766379</td>\n",
       "      <td>0.583619</td>\n",
       "      <td>4.115229</td>\n",
       "      <td>3.037180</td>\n",
       "      <td>-1.146759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519411</td>\n",
       "      <td>0.850307</td>\n",
       "      <td>-0.741573</td>\n",
       "      <td>1.164910</td>\n",
       "      <td>-0.739045</td>\n",
       "      <td>0.452370</td>\n",
       "      <td>0.133846</td>\n",
       "      <td>1.086331</td>\n",
       "      <td>0.885813</td>\n",
       "      <td>-0.038724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5380 rows Ã— 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1         2          3         4         5         6   \\\n",
       "0     10.781835 -10.550425 -1.389333  11.412608 -3.948730  0.184892  2.079231   \n",
       "1    -13.703336   0.700874  1.600031  -2.889409  5.369754  7.947973  0.806274   \n",
       "2      3.462429  -9.296243  1.776078  -2.945392  0.591712  2.946641 -2.010665   \n",
       "3     -4.334259  -4.577142  4.333773  -3.305378 -1.062078 -0.305052  2.860698   \n",
       "4      8.380139  -4.903977 -0.674055  -5.754902  4.575190  0.417406 -3.198909   \n",
       "...         ...        ...       ...        ...       ...       ...       ...   \n",
       "5375  -1.301857 -12.441267  6.887888   0.963782 -8.986152  2.616209  0.904449   \n",
       "5376  11.180929  -0.771640  6.697330  -3.333841 -0.178603  0.563499 -1.984782   \n",
       "5377  -0.348706  -8.609050  6.310708   0.992539  5.211123 -2.689503 -4.325625   \n",
       "5378  13.905367  -2.265077 -1.641486  -8.381800 -4.549641  1.352257 -3.287034   \n",
       "5379  -5.939059  -9.050252 -6.440438  -5.858641 -7.531106  0.766379  0.583619   \n",
       "\n",
       "            7         8         9   ...        74        75        76  \\\n",
       "0    -3.931734  0.882259 -0.292678  ...  0.308264 -0.216018  0.046164   \n",
       "1    -2.257151 -1.315446 -2.476533  ...  4.484327 -1.754804 -1.805732   \n",
       "2     4.974082 -1.538967 -2.179788  ... -0.615271  0.152359  0.110833   \n",
       "3     0.256052  0.939384 -2.921690  ...  0.217654  0.908828 -0.440344   \n",
       "4     2.866728 -8.067099  3.159759  ... -0.211351  2.108729 -0.738576   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5375  3.240487  1.895097 -1.648082  ... -1.035582 -0.785636  0.561686   \n",
       "5376  0.664532  0.099215 -1.652088  ...  0.414626 -0.474428 -0.698460   \n",
       "5377  0.290483 -1.422859  0.870810  ... -0.770339 -0.250563  0.919247   \n",
       "5378 -0.714738  2.623186  2.368429  ... -0.132435  1.109315  1.145495   \n",
       "5379  4.115229  3.037180 -1.146759  ...  0.519411  0.850307 -0.741573   \n",
       "\n",
       "            77        78        79        80        81        82        83  \n",
       "0    -0.064197 -0.052060  1.383777  0.782678 -0.844220  0.596582 -0.697189  \n",
       "1    -0.870102 -0.602934 -0.781125  4.719386  0.023884  0.813408  1.291091  \n",
       "2     0.351977 -0.917847 -0.105817  0.647814  0.202271 -0.120393  0.264436  \n",
       "3    -0.598833  0.288496 -1.316715  1.020567  1.088397  0.094585 -0.904364  \n",
       "4     1.180693 -0.598859  1.186879  1.795002 -0.179036  0.260185 -1.661345  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5375 -0.522764  0.655445 -0.246902 -0.684642  1.358684 -0.723941  1.488930  \n",
       "5376 -0.351142 -0.151871  0.043417  0.541379 -0.663330 -0.531068 -0.296129  \n",
       "5377 -0.606629  1.581885 -0.162867 -0.270071  0.274389  0.385588  0.320263  \n",
       "5378  1.482847 -0.486009 -0.134528 -0.146896  0.391888  1.089321 -0.227498  \n",
       "5379  1.164910 -0.739045  0.452370  0.133846  1.086331  0.885813 -0.038724  \n",
       "\n",
       "[5380 rows x 84 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.DataFrame(X)\n",
    "X.Cluster = db.labels_\n",
    "X = pd.get_dummies(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2999a26c",
   "metadata": {
    "id": "2999a26c"
   },
   "source": [
    "## Lasso Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0b1f40",
   "metadata": {
    "id": "eb0b1f40",
    "outputId": "8799cf2a-97c2-406a-a6ea-1e5b8ef6703b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>106.872299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>106.380806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>106.031425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>105.777853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>105.581103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.95</td>\n",
       "      <td>110.269018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.96</td>\n",
       "      <td>110.313407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.97</td>\n",
       "      <td>110.358386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.98</td>\n",
       "      <td>110.402973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.99</td>\n",
       "      <td>110.446627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha        rmse\n",
       "0    0.00  106.872299\n",
       "1    0.01  106.380806\n",
       "2    0.02  106.031425\n",
       "3    0.03  105.777853\n",
       "4    0.04  105.581103\n",
       "..    ...         ...\n",
       "95   0.95  110.269018\n",
       "96   0.96  110.313407\n",
       "97   0.97  110.358386\n",
       "98   0.98  110.402973\n",
       "99   0.99  110.446627\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "np.warnings.filterwarnings('ignore')\n",
    "\n",
    "#Tune alpha for lasso\n",
    "alphas = np.arange(0, 1, 0.01)\n",
    "score = pd.DataFrame(columns=['alpha', 'rmse'])\n",
    "for a in alphas:\n",
    "    lasso = Lasso(alpha=a)\n",
    "    lasso.fit(X, y)\n",
    "    \n",
    "    score = score.append(pd.DataFrame({'alpha':a, 'rmse':-cross_val_score(lasso, X, y, cv=5, scoring='neg_mean_squared_error').mean()}, index=[0]))\n",
    "\n",
    "score.reset_index(drop=True, inplace=True)\n",
    "score\n",
    "# score[score['rmse'].argmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc2bd90",
   "metadata": {
    "id": "3dc2bd90",
    "outputId": "610ad8a7-6353-4e5b-e97c-7350fae20ab4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alpha      0.120000\n",
       "rmse     104.968214\n",
       "Name: 12, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.loc[score['rmse'].argmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cb27bc",
   "metadata": {
    "id": "57cb27bc",
    "outputId": "3980abdc-09df-43bc-ad78-24c538dd8f93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.12)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to select most important variables - Linear predictor Lasso\n",
    "# lasso = Lasso(alpha=0.11)\n",
    "lasso = Lasso(alpha=0.12)\n",
    "lasso.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7e5e6f",
   "metadata": {
    "id": "0e7e5e6f"
   },
   "outputs": [],
   "source": [
    "nonzero_ind = np.nonzero(lasso.coef_)[0]\n",
    "\n",
    "# selected_features = features[nonzero_ind]\n",
    "nonzero_coef = lasso.coef_[nonzero_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8208f3",
   "metadata": {
    "id": "bc8208f3"
   },
   "outputs": [],
   "source": [
    "#Lasso selected linear features\n",
    "# selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826dc5c6",
   "metadata": {
    "id": "826dc5c6",
    "outputId": "c2b802f9-2ab9-4953-a29f-ed89d3ae8c53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.14275199, -0.23510107,  0.0277144 ,  0.19231137, -0.51833457,\n",
       "        0.24334847, -0.09128751,  0.20724417,  0.53592502,  0.01858758,\n",
       "        0.31715062, -0.2193871 , -0.34929397,  0.30907689,  0.0130048 ,\n",
       "       -0.28564128,  0.52294982,  0.04038266, -0.00797741,  0.5975163 ,\n",
       "        0.11208118,  0.38664439,  0.31635172, -0.19501142,  0.26545255,\n",
       "       -0.22400024,  0.00765458,  0.08262229,  0.05121642, -0.21045143,\n",
       "        0.16244109,  0.15750532,  0.12145783,  0.16813354, -0.18130663,\n",
       "        0.02310353,  0.26982112, -0.08128102, -0.0313459 ,  0.50070969,\n",
       "        0.24782428, -0.28985336, -0.0017511 ,  0.3020427 ,  0.11105345,\n",
       "        0.18757939,  0.25868654,  0.09910263, -0.06519453,  0.13485489,\n",
       "       -0.15899085, -0.26587851,  0.0760788 ,  0.32365502, -0.19365908,\n",
       "       -0.15152307, -0.01420895, -0.41576724, -0.63889593,  0.04148288,\n",
       "       -0.06306242, -0.41909471,  0.15760093, -0.05623522,  0.25332703,\n",
       "       -0.21227349,  0.25595593,  0.11495935,  0.16910699,  0.20902291,\n",
       "        0.37664969, -0.31284568, -0.19558434,  0.26909297, -0.07886084,\n",
       "        0.21513772, -0.20034809, -0.26529795,  0.34084752,  0.34606921,\n",
       "       -0.02720879, -0.0806762 ,  0.11002789, -0.12386596,  0.18953676,\n",
       "       -0.21414073,  0.18382677,  0.10510188])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afbf938",
   "metadata": {
    "id": "5afbf938",
    "outputId": "748fd110-5ec8-4915-bf7e-e180b20a0724"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'selected_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-c3126983aeea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfselected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Feature'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mselected_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Coef'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnonzero_coef\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdfselected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Coef'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'selected_features' is not defined"
     ]
    }
   ],
   "source": [
    "dfselected = pd.DataFrame({'Feature':selected_features, 'Coef':nonzero_coef})\n",
    "dfselected.sort_values('Coef', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2db02d9",
   "metadata": {
    "id": "f2db02d9",
    "outputId": "f45df337-5691-4269-eaf9-e1aaf8200e22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.99099033685015"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training on linear lasso regression\n",
    "train_pred = lasso.predict(X)\n",
    "train_rmse = np.sqrt(mean_squared_error(y, train_pred))\n",
    "train_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73af41f",
   "metadata": {
    "id": "f73af41f"
   },
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac8923e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "ac8923e6",
    "outputId": "dfbafe95-0971-4c06-9b07-8bb190a80e04"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=10, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=10, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor(max_depth=10, random_state=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "X = pd.DataFrame(X)\n",
    "features = X.columns\n",
    "\n",
    "#Defining the object to build a regression tree\n",
    "model = DecisionTreeRegressor(random_state=1, max_depth=10) \n",
    "\n",
    "#Fitting the regression tree to the data\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8922e21f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "id": "8922e21f",
    "outputId": "d5e26055-86f5-4e37-96ce-776c7fd6fa71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5380, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-47e35288-2ba0-41d6-b4e6-795c6a34d00d\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>27</th>\n",
       "      <th>4</th>\n",
       "      <th>3</th>\n",
       "      <th>19</th>\n",
       "      <th>23</th>\n",
       "      <th>82</th>\n",
       "      <th>21</th>\n",
       "      <th>17</th>\n",
       "      <th>83</th>\n",
       "      <th>1</th>\n",
       "      <th>89</th>\n",
       "      <th>34</th>\n",
       "      <th>78</th>\n",
       "      <th>73</th>\n",
       "      <th>44</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.216445</td>\n",
       "      <td>-1.446733</td>\n",
       "      <td>2.627208</td>\n",
       "      <td>-3.581319</td>\n",
       "      <td>0.049754</td>\n",
       "      <td>-2.313434</td>\n",
       "      <td>0.775154</td>\n",
       "      <td>0.004809</td>\n",
       "      <td>0.540930</td>\n",
       "      <td>0.027618</td>\n",
       "      <td>2.495877</td>\n",
       "      <td>-0.090713</td>\n",
       "      <td>-0.293449</td>\n",
       "      <td>-1.153108</td>\n",
       "      <td>-0.379833</td>\n",
       "      <td>0.018940</td>\n",
       "      <td>0.619172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.140446</td>\n",
       "      <td>1.663039</td>\n",
       "      <td>1.094582</td>\n",
       "      <td>-0.844141</td>\n",
       "      <td>-1.007747</td>\n",
       "      <td>-0.011230</td>\n",
       "      <td>-0.706094</td>\n",
       "      <td>0.654055</td>\n",
       "      <td>-0.225389</td>\n",
       "      <td>0.311117</td>\n",
       "      <td>-5.001596</td>\n",
       "      <td>-0.375138</td>\n",
       "      <td>-0.924607</td>\n",
       "      <td>-0.400816</td>\n",
       "      <td>0.089035</td>\n",
       "      <td>-0.760775</td>\n",
       "      <td>0.808711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.691202</td>\n",
       "      <td>1.557346</td>\n",
       "      <td>0.340869</td>\n",
       "      <td>0.355307</td>\n",
       "      <td>-0.220071</td>\n",
       "      <td>1.044560</td>\n",
       "      <td>0.391508</td>\n",
       "      <td>-2.189326</td>\n",
       "      <td>1.694945</td>\n",
       "      <td>-0.072165</td>\n",
       "      <td>-1.810675</td>\n",
       "      <td>0.083189</td>\n",
       "      <td>-1.017777</td>\n",
       "      <td>-0.470520</td>\n",
       "      <td>-0.289166</td>\n",
       "      <td>0.868379</td>\n",
       "      <td>0.249256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.082068</td>\n",
       "      <td>0.620745</td>\n",
       "      <td>0.053721</td>\n",
       "      <td>-0.024098</td>\n",
       "      <td>-1.152237</td>\n",
       "      <td>0.742078</td>\n",
       "      <td>-0.754713</td>\n",
       "      <td>2.192277</td>\n",
       "      <td>0.599513</td>\n",
       "      <td>-1.416460</td>\n",
       "      <td>-1.129349</td>\n",
       "      <td>-1.198509</td>\n",
       "      <td>-0.281056</td>\n",
       "      <td>0.346986</td>\n",
       "      <td>-0.858476</td>\n",
       "      <td>0.360902</td>\n",
       "      <td>1.330526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.100408</td>\n",
       "      <td>1.022988</td>\n",
       "      <td>-3.607955</td>\n",
       "      <td>-1.772313</td>\n",
       "      <td>2.156620</td>\n",
       "      <td>0.969083</td>\n",
       "      <td>0.448184</td>\n",
       "      <td>-0.581930</td>\n",
       "      <td>-1.247286</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>2.521909</td>\n",
       "      <td>1.045976</td>\n",
       "      <td>-1.004576</td>\n",
       "      <td>0.663698</td>\n",
       "      <td>1.200070</td>\n",
       "      <td>-0.355641</td>\n",
       "      <td>1.093060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5375</th>\n",
       "      <td>-6.051853</td>\n",
       "      <td>-0.015470</td>\n",
       "      <td>2.065510</td>\n",
       "      <td>0.926658</td>\n",
       "      <td>0.865128</td>\n",
       "      <td>0.652321</td>\n",
       "      <td>1.105818</td>\n",
       "      <td>2.837176</td>\n",
       "      <td>-1.053877</td>\n",
       "      <td>-0.412934</td>\n",
       "      <td>-4.311729</td>\n",
       "      <td>0.221589</td>\n",
       "      <td>1.418244</td>\n",
       "      <td>0.112751</td>\n",
       "      <td>0.685252</td>\n",
       "      <td>-0.466833</td>\n",
       "      <td>-1.638644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5376</th>\n",
       "      <td>-3.063057</td>\n",
       "      <td>1.592699</td>\n",
       "      <td>2.488758</td>\n",
       "      <td>0.105321</td>\n",
       "      <td>1.522261</td>\n",
       "      <td>-0.137987</td>\n",
       "      <td>-0.335089</td>\n",
       "      <td>0.049325</td>\n",
       "      <td>-0.161518</td>\n",
       "      <td>0.186035</td>\n",
       "      <td>1.531610</td>\n",
       "      <td>0.640383</td>\n",
       "      <td>0.870638</td>\n",
       "      <td>0.064573</td>\n",
       "      <td>-0.186071</td>\n",
       "      <td>-0.740833</td>\n",
       "      <td>-0.850912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5377</th>\n",
       "      <td>-1.147356</td>\n",
       "      <td>-0.221381</td>\n",
       "      <td>0.334721</td>\n",
       "      <td>-2.430359</td>\n",
       "      <td>0.635739</td>\n",
       "      <td>1.821866</td>\n",
       "      <td>-0.244164</td>\n",
       "      <td>-0.028878</td>\n",
       "      <td>-0.249185</td>\n",
       "      <td>-0.233368</td>\n",
       "      <td>-0.329800</td>\n",
       "      <td>-0.770135</td>\n",
       "      <td>0.711080</td>\n",
       "      <td>0.380176</td>\n",
       "      <td>0.590239</td>\n",
       "      <td>-0.568166</td>\n",
       "      <td>0.023760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td>-4.393695</td>\n",
       "      <td>-0.585629</td>\n",
       "      <td>-0.167325</td>\n",
       "      <td>0.908254</td>\n",
       "      <td>-2.135821</td>\n",
       "      <td>-1.375929</td>\n",
       "      <td>-0.766120</td>\n",
       "      <td>-1.504066</td>\n",
       "      <td>2.443287</td>\n",
       "      <td>-0.536060</td>\n",
       "      <td>2.484050</td>\n",
       "      <td>-0.237645</td>\n",
       "      <td>-0.860227</td>\n",
       "      <td>1.330484</td>\n",
       "      <td>0.252563</td>\n",
       "      <td>-0.017245</td>\n",
       "      <td>-1.947680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5379</th>\n",
       "      <td>-4.564769</td>\n",
       "      <td>-1.119056</td>\n",
       "      <td>-1.250938</td>\n",
       "      <td>1.354188</td>\n",
       "      <td>-0.241513</td>\n",
       "      <td>-0.737374</td>\n",
       "      <td>0.018228</td>\n",
       "      <td>-0.812878</td>\n",
       "      <td>-0.524783</td>\n",
       "      <td>-0.219668</td>\n",
       "      <td>-8.323425</td>\n",
       "      <td>0.070518</td>\n",
       "      <td>1.904866</td>\n",
       "      <td>0.535298</td>\n",
       "      <td>-0.634019</td>\n",
       "      <td>1.490553</td>\n",
       "      <td>2.615812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5380 rows Ã— 17 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47e35288-2ba0-41d6-b4e6-795c6a34d00d')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-47e35288-2ba0-41d6-b4e6-795c6a34d00d button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-47e35288-2ba0-41d6-b4e6-795c6a34d00d');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "            0         27        4         3         19        23        82  \\\n",
       "0    -4.216445 -1.446733  2.627208 -3.581319  0.049754 -2.313434  0.775154   \n",
       "1     5.140446  1.663039  1.094582 -0.844141 -1.007747 -0.011230 -0.706094   \n",
       "2    -1.691202  1.557346  0.340869  0.355307 -0.220071  1.044560  0.391508   \n",
       "3     0.082068  0.620745  0.053721 -0.024098 -1.152237  0.742078 -0.754713   \n",
       "4    -0.100408  1.022988 -3.607955 -1.772313  2.156620  0.969083  0.448184   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5375 -6.051853 -0.015470  2.065510  0.926658  0.865128  0.652321  1.105818   \n",
       "5376 -3.063057  1.592699  2.488758  0.105321  1.522261 -0.137987 -0.335089   \n",
       "5377 -1.147356 -0.221381  0.334721 -2.430359  0.635739  1.821866 -0.244164   \n",
       "5378 -4.393695 -0.585629 -0.167325  0.908254 -2.135821 -1.375929 -0.766120   \n",
       "5379 -4.564769 -1.119056 -1.250938  1.354188 -0.241513 -0.737374  0.018228   \n",
       "\n",
       "            21        17        83        1         89        34        78  \\\n",
       "0     0.004809  0.540930  0.027618  2.495877 -0.090713 -0.293449 -1.153108   \n",
       "1     0.654055 -0.225389  0.311117 -5.001596 -0.375138 -0.924607 -0.400816   \n",
       "2    -2.189326  1.694945 -0.072165 -1.810675  0.083189 -1.017777 -0.470520   \n",
       "3     2.192277  0.599513 -1.416460 -1.129349 -1.198509 -0.281056  0.346986   \n",
       "4    -0.581930 -1.247286  0.001873  2.521909  1.045976 -1.004576  0.663698   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5375  2.837176 -1.053877 -0.412934 -4.311729  0.221589  1.418244  0.112751   \n",
       "5376  0.049325 -0.161518  0.186035  1.531610  0.640383  0.870638  0.064573   \n",
       "5377 -0.028878 -0.249185 -0.233368 -0.329800 -0.770135  0.711080  0.380176   \n",
       "5378 -1.504066  2.443287 -0.536060  2.484050 -0.237645 -0.860227  1.330484   \n",
       "5379 -0.812878 -0.524783 -0.219668 -8.323425  0.070518  1.904866  0.535298   \n",
       "\n",
       "            73        44        57  \n",
       "0    -0.379833  0.018940  0.619172  \n",
       "1     0.089035 -0.760775  0.808711  \n",
       "2    -0.289166  0.868379  0.249256  \n",
       "3    -0.858476  0.360902  1.330526  \n",
       "4     1.200070 -0.355641  1.093060  \n",
       "...        ...       ...       ...  \n",
       "5375  0.685252 -0.466833 -1.638644  \n",
       "5376 -0.186071 -0.740833 -0.850912  \n",
       "5377  0.590239 -0.568166  0.023760  \n",
       "5378  0.252563 -0.017245 -1.947680  \n",
       "5379 -0.634019  1.490553  2.615812  \n",
       "\n",
       "[5380 rows x 17 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfimportances = pd.DataFrame({'Feature':features, 'Importance':model.feature_importances_})\n",
    "dfimportances = dfimportances.sort_values('Importance', ascending=False)\n",
    "nonzero = dfimportances[dfimportances['Importance'] > 0.01]\n",
    "selected = X.loc[:, nonzero['Feature']]\n",
    "\n",
    "X = selected\n",
    "print(X.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a311271b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a311271b",
    "outputId": "64e3aa14-0c95-4f0e-d1f1-2b1b8cd7e150"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "print(dfimportances[dfimportances['Importance'] > 0.01].shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd967753",
   "metadata": {
    "id": "dd967753"
   },
   "source": [
    "#### 18 Columns remain After correlation, pca, selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce4138f",
   "metadata": {
    "id": "2ce4138f"
   },
   "source": [
    "## Segmented Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774fb622",
   "metadata": {
    "id": "774fb622"
   },
   "outputs": [],
   "source": [
    "clusters = KMeans(random_state=0, n_clusters = 2)\n",
    "clusters.fit(X)\n",
    "\n",
    "pred = clusters.predict(X)\n",
    "X['Cluster'] = pred\n",
    "X.Cluster = X.Cluster.astype(int)\n",
    "\n",
    "X0 = X.loc[X.Cluster == 0].drop('Cluster', axis=1)\n",
    "y0 = y.loc[y.index.isin(X0.index)]\n",
    "\n",
    "\n",
    "X1 = X.loc[X.Cluster == 1].drop('Cluster', axis=1)\n",
    "y1 = y.loc[y.index.isin(X1.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1c3b8f",
   "metadata": {
    "id": "ca1c3b8f",
    "outputId": "d3e35dbd-19b2-4ffd-c841-0e10867ce7ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alpha    0.01000\n",
       "rmse     0.55864\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune 2 seperate lassos\n",
    "np.warnings.filterwarnings('ignore')\n",
    "\n",
    "alphas = np.arange(0, 1, 0.01)\n",
    "score = pd.DataFrame(columns=['alpha', 'rmse'])\n",
    "for a in alphas:\n",
    "    lasso = Lasso(alpha=a)\n",
    "    lasso.fit(X0, y0)\n",
    "    \n",
    "    score = score.append(pd.DataFrame({'alpha':a, 'rmse':-cross_val_score(lasso, X0, y0, cv=5, scoring='neg_mean_squared_error').mean()}, index=[0]))\n",
    "\n",
    "score.reset_index(drop=True, inplace=True)\n",
    "score.loc[score['rmse'].argmin()]\n",
    "\n",
    "model0 = lasso(alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3b5c77",
   "metadata": {
    "id": "4e3b5c77",
    "outputId": "a25bf9bc-5f56-47e7-9b99-5aeebda9ff19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alpha    0.020000\n",
       "rmse     0.489813\n",
       "Name: 2, dtype: float64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = pd.DataFrame(columns=['alpha', 'rmse'])\n",
    "for a in alphas:\n",
    "    lasso = Lasso(alpha=a)\n",
    "    lasso.fit(X1, y1)\n",
    "    \n",
    "    score = score.append(pd.DataFrame({'alpha':a, 'rmse':-cross_val_score(lasso, X1, y1, cv=5, scoring='neg_mean_squared_error').mean()}, index=[0]))\n",
    "\n",
    "score.reset_index(drop=True, inplace=True)\n",
    "score.loc[score['rmse'].argmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d12b82",
   "metadata": {
    "id": "f0d12b82"
   },
   "outputs": [],
   "source": [
    "model0 = lasso(alpha=0.01).fit(X0, y0)\n",
    "model0 = lasso(alpha=0.02).fit(X1, y1)\n",
    "\n",
    "# Not very helpful here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207a926c",
   "metadata": {
    "id": "207a926c"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa65cbf2",
   "metadata": {
    "id": "fa65cbf2",
    "outputId": "2f1a1bec-d338-43bc-d46d-3b42b1c36dac"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-06a12ea5a351>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                                  \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                   \u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                                   n_jobs=-1).fit(X,y)\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0moob_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moob_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/main/lib/python3.6/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    391\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 393\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/main/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/main/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/main/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/main/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/main/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/main/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "params = {'n_estimators': [500],\n",
    "          'max_depth': [12,15,18],\n",
    "          'max_leaf_nodes':[1100,1200,1300],\n",
    "          'max_features': [0.2,0.4,0.6,0.8]}\n",
    "\n",
    "# param_list=list(it.product(*(params[Name] for Name in params)))\n",
    "\n",
    "# oob_score = [0]*len(param_list)\n",
    "# i=0\n",
    "# for pr in param_list:\n",
    "#     model = RandomForestRegressor(random_state=1,oob_score=True,verbose=False,n_estimators = pr[0],\n",
    "#                                  max_depth=pr[1],\n",
    "#                                   max_leaf_nodes=pr[2],max_features=pr[3],\n",
    "#                                   n_jobs=-1).fit(X,y)\n",
    "#     oob_score[i] = model.oob_score_\n",
    "#     i=i+1\n",
    "    \n",
    "# end_time = time.time()\n",
    "# print(\"time taken = \", (end_time-start_time)/60, \" minutes\")\n",
    "# print(\"Best params = \", param_list[np.argmax(oob_score)])\n",
    "# print(\"Best score (R-squared) = \", np.max(oob_score))\n",
    "\n",
    "#Strong overfitting - try k-fold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec69279",
   "metadata": {
    "id": "2ec69279",
    "outputId": "f1f142ef-cdd5-4f3c-bca7-a625b55588bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukelilienthal/opt/anaconda3/envs/main/lib/python3.6/site-packages/joblib/externals/loky/backend/utils.py:63: UserWarning: Failed to kill subprocesses on this platform. Please installpsutil: https://github.com/giampaolo/psutil\n",
      "Details:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lukelilienthal/opt/anaconda3/envs/main/lib/python3.6/site-packages/joblib/externals/loky/backend/utils.py\", line 59, in _kill_process_tree_without_psutil\n",
      "    _posix_recursive_kill(process.pid)\n",
      "  File \"/Users/lukelilienthal/opt/anaconda3/envs/main/lib/python3.6/site-packages/joblib/externals/loky/backend/utils.py\", line 111, in _posix_recursive_kill\n",
      "    [\"pgrep\", \"-P\", str(pid)], stderr=None, text=True\n",
      "  File \"/Users/lukelilienthal/opt/anaconda3/envs/main/lib/python3.6/subprocess.py\", line 356, in check_output\n",
      "    **kwargs).stdout\n",
      "  File \"/Users/lukelilienthal/opt/anaconda3/envs/main/lib/python3.6/subprocess.py\", line 423, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "TypeError: __init__() got an unexpected keyword argument 'text'\n",
      "\n",
      "  \"Failed to kill subprocesses on this platform. Please install\"\n",
      "Exception in thread ExecutorManagerThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lukelilienthal/opt/anaconda3/envs/main/lib/python3.6/site-packages/joblib/externals/loky/backend/utils.py\", line 59, in _kill_process_tree_without_psutil\n",
      "    _posix_recursive_kill(process.pid)\n",
      "  File \"/Users/lukelilienthal/opt/anaconda3/envs/main/lib/python3.6/site-packages/joblib/externals/loky/backend/utils.py\", line 111, in _posix_recursive_kill\n",
      "    [\"pgrep\", \"-P\", str(pid)], stderr=None, text=True\n",
      "  File \"/Users/lukelilienthal/opt/anaconda3/envs/main/lib/python3.6/subprocess.py\", line 356, in check_output\n",
      "    **kwargs).stdout\n",
      "  File \"/Users/lukelilienthal/opt/anaconda3/envs/main/lib/python3.6/subprocess.py\", line 423, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "TypeError: __init__() got an unexpected keyword argument 'text'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lukelilienthal/opt/anaconda3/envs/main/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/lukelilienthal/opt/anaconda3/envs/main/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py\", line 569, in run\n",
      "    self.flag_executor_shutting_down()\n",
      "  File \"/Users/lukelilienthal/opt/anaconda3/envs/main/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py\", line 769, in flag_executor_shutting_down\n",
      "    self.kill_workers(reason=\"executor shutting down\")\n",
      "  File \"/Users/lukelilienthal/opt/anaconda3/envs/main/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py\", line 779, in kill_workers\n",
      "    kill_process_tree(p)\n",
      "  File \"/Users/lukelilienthal/opt/anaconda3/envs/main/lib/python3.6/site-packages/joblib/externals/loky/backend/utils.py\", line 20, in kill_process_tree\n",
      "    _kill_process_tree_without_psutil(process)\n",
      "  File \"/Users/lukelilienthal/opt/anaconda3/envs/main/lib/python3.6/site-packages/joblib/externals/loky/backend/utils.py\", line 72, in _kill_process_tree_without_psutil\n",
      "    process.kill()\n",
      "AttributeError: 'LokyProcess' object has no attribute 'kill'\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-886ce1b595a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_squared_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/main/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/main/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/main/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/main/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[1;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/main/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/main/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/main/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    565\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/main/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/main/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "params = {'n_estimators': [400],\n",
    "          'max_depth': [5,15,25],\n",
    "          'max_leaf_nodes':[500,1000,1500],\n",
    "          'max_features': [0.3, 0.6, 0.9]}\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "grid = GridSearchCV(RandomForestRegressor(), n_jobs=-1, param_grid=params, cv=cv, scoring='neg_mean_squared_error')\n",
    "grid.fit(X, y)\n",
    "\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b70cd32",
   "metadata": {
    "id": "5b70cd32",
    "outputId": "f8cbcb50-b138-446e-c202-180e11a9542f"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-28c2e4d7952c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898b077a",
   "metadata": {
    "id": "898b077a",
    "outputId": "a3d42d2b-b324-4025-ad1b-dd3e1e17ccc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4440577123502503"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(random_state=1,verbose=False,n_estimators = 400, max_depth=15,\n",
    "                                  max_leaf_nodes=500,max_features=0.6,\n",
    "                                  n_jobs=-1).fit(X,y)\n",
    "\n",
    "np.sqrt(mean_squared_error(y, model.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdabe06a",
   "metadata": {
    "id": "bdabe06a"
   },
   "source": [
    "## Train rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cebb356",
   "metadata": {
    "id": "0cebb356",
    "outputId": "5531a236-6d7e-4e0d-a216-8d656be10841",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4010586422061422"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred = model.predict(X)\n",
    "train_rmse = np.sqrt(mean_squared_error(y, train_pred))\n",
    "train_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47989222",
   "metadata": {
    "id": "47989222"
   },
   "source": [
    "## ADABoost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c34c020",
   "metadata": {
    "id": "3c34c020"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd14a64e",
   "metadata": {
    "id": "fd14a64e"
   },
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9658a886",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9658a886",
    "outputId": "75ed8cc6-aed0-4dc4-9d2a-1f53f1c188a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n",
      "Optimal parameter values = {'subsample': 0.5, 'reg_lambda': 1, 'n_estimators': 1000, 'max_depth': 4, 'learning_rate': 0.01, 'gamma': 0, 'colsample_bytree': 0.75}\n",
      "Optimal cross validation R-squared =  -0.6293635387441705\n"
     ]
    }
   ],
   "source": [
    "# Run with 17 predictors and 100 iterations (5cv) on colab (500)- 2 min\n",
    "# Run with 17 predictors and All iterations (2cv) on colab (4374) -  16 min\n",
    "# Run with 17 predictions and 1000 iterations (5cv) on colab (5000) - 30 min\n",
    "\n",
    "\n",
    "# Coarse grid search\n",
    "# Tune this\n",
    "param_grid = {'max_depth': [4,6,8],\n",
    "              'learning_rate': [0.01, 0.05, 0.1],\n",
    "               'reg_lambda':[0, 1, 10],\n",
    "                'n_estimators':[100, 500, 1000],\n",
    "                'gamma': [0, 10, 100],\n",
    "                'subsample': [0.5, 0.75, 1.0],\n",
    "                'colsample_bytree': [0.5, 0.75, 1.0]}\n",
    "\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=1)\n",
    "optimal_params = RandomizedSearchCV(estimator=xgb.XGBRegressor(random_state=1),                                                       \n",
    "                             param_distributions = param_grid,\n",
    "                             n_iter=1000,\n",
    "                             verbose = 1,\n",
    "                             n_jobs=-1,\n",
    "                             cv = cv,\n",
    "                             scoring = 'neg_mean_squared_error')\n",
    "optimal_params.fit(X,y)\n",
    "print(\"Optimal parameter values =\", optimal_params.best_params_)\n",
    "print(\"Optimal cross validation R-squared = \",optimal_params.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "YxhC8NMgiCgZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YxhC8NMgiCgZ",
    "outputId": "f1a07ccb-0079-4f08-b308-a44beced06b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "Optimal parameter values = {'colsample_bytree': 0.85, 'gamma': 4, 'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 1000, 'reg_lambda': 1, 'subsample': 0.5}\n",
      "Optimal cross validation R-squared =  -0.6260674406599673\n"
     ]
    }
   ],
   "source": [
    "#Finer grid \n",
    "param_grid = {'max_depth': [4, 5, 6],\n",
    "              'learning_rate': [0.006, 0.008, 0.01],\n",
    "               'reg_lambda':[1, 2, 3],\n",
    "                'n_estimators':[1000],\n",
    "                'gamma': [3, 4, 5],\n",
    "                'subsample': [0.45, 0.5, 0.55],\n",
    "                'colsample_bytree': [0.75, 0.8, 0.85]}\n",
    "\n",
    "cv = KFold(n_splits=5,shuffle=True,random_state=1)\n",
    "optimal_params = GridSearchCV(estimator=xgb.XGBRegressor(random_state=1),                                                       \n",
    "                             param_grid = param_grid,\n",
    "                             verbose = 1,\n",
    "                             n_jobs=-1,\n",
    "                             cv = cv,\n",
    "                             scoring = 'neg_mean_squared_error')\n",
    "optimal_params.fit(X,y)\n",
    "print(\"Optimal parameter values =\", optimal_params.best_params_)\n",
    "print(\"Optimal cross validation R-squared = \",optimal_params.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b0f7fa3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0b0f7fa3",
    "outputId": "a76702df-d849-4445-d779-8f5c8292b3f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.210104159466688"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg = optimal_params.best_estimator_\n",
    "\n",
    "np.sqrt(mean_squared_error(np.exp(y), np.exp(xg.predict(X))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c749a4",
   "metadata": {
    "id": "17c749a4"
   },
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55188925",
   "metadata": {
    "id": "55188925",
    "outputId": "ce7103de-c408-4e8c-b1f8-cbf70af8d303"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4842 samples, validate on 538 samples\n",
      "Epoch 1/50\n",
      "4842/4842 [==============================] - 1s 163us/step - loss: 7.9978 - val_loss: 3.1414\n",
      "Epoch 2/50\n",
      "4842/4842 [==============================] - 0s 16us/step - loss: 3.4895 - val_loss: 1.4964\n",
      "Epoch 3/50\n",
      "4842/4842 [==============================] - 0s 16us/step - loss: 2.5283 - val_loss: 1.5729\n",
      "Epoch 4/50\n",
      "4842/4842 [==============================] - 0s 16us/step - loss: 2.4632 - val_loss: 1.3928\n",
      "Epoch 5/50\n",
      "4842/4842 [==============================] - 0s 16us/step - loss: 2.1447 - val_loss: 1.0932\n",
      "Epoch 6/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 1.7047 - val_loss: 1.0286\n",
      "Epoch 7/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 1.6339 - val_loss: 1.0301\n",
      "Epoch 8/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 1.4777 - val_loss: 0.9913\n",
      "Epoch 9/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 1.4051 - val_loss: 0.9373\n",
      "Epoch 10/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 1.3844 - val_loss: 0.8980\n",
      "Epoch 11/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 1.3223 - val_loss: 0.8699\n",
      "Epoch 12/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 1.2752 - val_loss: 0.8511\n",
      "Epoch 13/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 1.2155 - val_loss: 0.8380\n",
      "Epoch 14/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 1.1474 - val_loss: 0.8285\n",
      "Epoch 15/50\n",
      "4842/4842 [==============================] - 0s 15us/step - loss: 1.1269 - val_loss: 0.8198\n",
      "Epoch 16/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 1.1335 - val_loss: 0.8065\n",
      "Epoch 17/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 1.0719 - val_loss: 0.7937\n",
      "Epoch 18/50\n",
      "4842/4842 [==============================] - 0s 15us/step - loss: 1.0816 - val_loss: 0.7827\n",
      "Epoch 19/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 1.0205 - val_loss: 0.7746\n",
      "Epoch 20/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 0.9963 - val_loss: 0.7689\n",
      "Epoch 21/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 0.9407 - val_loss: 0.7669\n",
      "Epoch 22/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 0.9666 - val_loss: 0.7648\n",
      "Epoch 23/50\n",
      "4842/4842 [==============================] - 0s 15us/step - loss: 0.9611 - val_loss: 0.7596\n",
      "Epoch 24/50\n",
      "4842/4842 [==============================] - 0s 15us/step - loss: 0.9353 - val_loss: 0.7546\n",
      "Epoch 25/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 0.9321 - val_loss: 0.7489\n",
      "Epoch 26/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 0.8735 - val_loss: 0.7443\n",
      "Epoch 27/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 0.8971 - val_loss: 0.7427\n",
      "Epoch 28/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 0.8611 - val_loss: 0.7405\n",
      "Epoch 29/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 0.8774 - val_loss: 0.7378\n",
      "Epoch 30/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 0.8582 - val_loss: 0.7311\n",
      "Epoch 31/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 0.8500 - val_loss: 0.7263\n",
      "Epoch 32/50\n",
      "4842/4842 [==============================] - 0s 15us/step - loss: 0.8527 - val_loss: 0.7224\n",
      "Epoch 33/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 0.8417 - val_loss: 0.7172\n",
      "Epoch 34/50\n",
      "4842/4842 [==============================] - 0s 15us/step - loss: 0.8201 - val_loss: 0.7134\n",
      "Epoch 35/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 0.8331 - val_loss: 0.7118\n",
      "Epoch 36/50\n",
      "4842/4842 [==============================] - 0s 15us/step - loss: 0.7856 - val_loss: 0.7096\n",
      "Epoch 37/50\n",
      "4842/4842 [==============================] - 0s 15us/step - loss: 0.7764 - val_loss: 0.7070\n",
      "Epoch 38/50\n",
      "4842/4842 [==============================] - 0s 15us/step - loss: 0.7617 - val_loss: 0.7049\n",
      "Epoch 39/50\n",
      "4842/4842 [==============================] - 0s 15us/step - loss: 0.7829 - val_loss: 0.7030\n",
      "Epoch 40/50\n",
      "4842/4842 [==============================] - 0s 15us/step - loss: 0.7580 - val_loss: 0.7037\n",
      "Epoch 41/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 0.7783 - val_loss: 0.7015\n",
      "Epoch 42/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 0.7654 - val_loss: 0.6980\n",
      "Epoch 43/50\n",
      "4842/4842 [==============================] - 0s 15us/step - loss: 0.7137 - val_loss: 0.6986\n",
      "Epoch 44/50\n",
      "4842/4842 [==============================] - 0s 15us/step - loss: 0.7765 - val_loss: 0.6980\n",
      "Epoch 45/50\n",
      "4842/4842 [==============================] - 0s 15us/step - loss: 0.7212 - val_loss: 0.6985\n",
      "Epoch 46/50\n",
      "4842/4842 [==============================] - 0s 15us/step - loss: 0.7216 - val_loss: 0.6948\n",
      "Epoch 47/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 0.7178 - val_loss: 0.6920\n",
      "Epoch 48/50\n",
      "4842/4842 [==============================] - 0s 14us/step - loss: 0.7160 - val_loss: 0.6939\n",
      "Epoch 49/50\n",
      "4842/4842 [==============================] - 0s 15us/step - loss: 0.7007 - val_loss: 0.6896\n",
      "Epoch 50/50\n",
      "4842/4842 [==============================] - 0s 15us/step - loss: 0.6906 - val_loss: 0.6819\n"
     ]
    }
   ],
   "source": [
    "# Learn how to tune this\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "import tensorflow as tf\n",
    "# tf.config.run_functions_eagerly(True) #Causing error for me\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer, Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "network = Sequential()\n",
    "network.add(InputLayer(input_shape=(191,)))\n",
    "# network.add(Dense(500, activation='linear'))\n",
    "# network.add(Dense(200, activation='relu'))\n",
    "network.add(Dense(100, activation='relu'))\n",
    "network.add(Dropout(0.3))\n",
    "network.add(Dense(50, activation='relu', kernel_initializer='he_normal'))\n",
    "network.add(Dropout(0.3))\n",
    "network.add(Dense(1, activation='linear'))\n",
    "\n",
    "network.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "history = network.fit(X, y, epochs=50, batch_size=1000, validation_split=0.1,\n",
    "                      callbacks=[EarlyStopping('val_loss', patience=int(10))])\n",
    "\n",
    "nn = network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a44e1e7",
   "metadata": {
    "id": "3a44e1e7",
    "outputId": "c1057dc4-cb39-4d01-9b6a-e58f2125d68b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "plt.plot(history.history['loss'][1:])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ddb22a",
   "metadata": {
    "id": "d8ddb22a"
   },
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0245ec",
   "metadata": {
    "id": "9c0245ec",
    "outputId": "19eaf638-9f96-43f7-8f86-3feff6ddbd78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5380, 191)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor, VotingClassifier, StackingRegressor, StackingClassifier, GradientBoostingRegressor,GradientBoostingClassifier, BaggingRegressor,BaggingClassifier,RandomForestRegressor,RandomForestClassifier,AdaBoostRegressor,AdaBoostClassifier\n",
    "\n",
    "# RF, XGBoost, Neural Network, lasso\n",
    "en = StackingRegressor(estimators = [('xgb', xg),('nn', nn),('rf', rf),('lasso', lasso)],\n",
    "                     final_estimator=LinearRegression(),                                          \n",
    "                    cv = KFold(n_splits = 5, shuffle = True, random_state=1))\n",
    "en.fit(X,y)\n",
    "\n",
    "en.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe5924b",
   "metadata": {
    "id": "bbe5924b"
   },
   "source": [
    "## Segmented Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f8c5a1",
   "metadata": {
    "id": "48f8c5a1"
   },
   "outputs": [],
   "source": [
    "#Based on clustering, run differently tuned regressions on groups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c089ea",
   "metadata": {
    "id": "90c089ea"
   },
   "source": [
    "## Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f65f99d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f65f99d9",
    "outputId": "f55c7b8c-edaa-4eb8-b180-283c7508591b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4403, 17)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5.4301934, 8.249057 , 2.5768306, ..., 6.8120832, 8.22978  ,\n",
       "       8.248733 ], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Predictions\n",
    "data = pd.read_csv('test.csv')\n",
    "id = data.id\n",
    "\n",
    "data = data.drop(nan_col, axis=1)\n",
    "\n",
    "imputer = impute.KNNImputer(n_neighbors=5)\n",
    "data = imputer.fit_transform(data)\n",
    "\n",
    "# clusters = KMeans(random_state=0, n_clusters = 10)\n",
    "# clusters.fit(data)\n",
    "# pred = clusters.predict(data)\n",
    "# data['Cluster'] = pred\n",
    "# data.Cluster = data.Cluster.astype(str)\n",
    "\n",
    "data = scaler.transform(data)\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "data = data.drop(res, axis=1)\n",
    "data = data.drop(columns=drops, axis=1)\n",
    "\n",
    "data = pca.transform(data)\n",
    "\n",
    "data = pd.DataFrame(data)\n",
    "data = data.loc[:, nonzero['Feature']]\n",
    "print(data.shape)\n",
    "\n",
    "test_pred = np.exp(xg.predict(data))\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "430e11cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "430e11cd",
    "outputId": "47568196-bbd7-4bad-e5d1-8db5978b1b54"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0a15525b-39b5-4b32-a1df-04dd0d499dd2\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5380</td>\n",
       "      <td>5.430193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5381</td>\n",
       "      <td>8.249057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5382</td>\n",
       "      <td>2.576831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5383</td>\n",
       "      <td>5.787326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5384</td>\n",
       "      <td>6.868587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>9778</td>\n",
       "      <td>1.804357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>9779</td>\n",
       "      <td>6.549759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>9780</td>\n",
       "      <td>6.812083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>9781</td>\n",
       "      <td>8.229780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4402</th>\n",
       "      <td>9782</td>\n",
       "      <td>8.248733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4403 rows Ã— 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a15525b-39b5-4b32-a1df-04dd0d499dd2')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-0a15525b-39b5-4b32-a1df-04dd0d499dd2 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-0a15525b-39b5-4b32-a1df-04dd0d499dd2');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "        id         y\n",
       "0     5380  5.430193\n",
       "1     5381  8.249057\n",
       "2     5382  2.576831\n",
       "3     5383  5.787326\n",
       "4     5384  6.868587\n",
       "...    ...       ...\n",
       "4398  9778  1.804357\n",
       "4399  9779  6.549759\n",
       "4400  9780  6.812083\n",
       "4401  9781  8.229780\n",
       "4402  9782  8.248733\n",
       "\n",
       "[4403 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame()\n",
    "output['id'] = id\n",
    "output['y'] = test_pred\n",
    "\n",
    "output.loc[output['y']<0, 'y'] = 0\n",
    "output.loc[output['y']>100, 'y'] = 100\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "79848c35",
   "metadata": {
    "id": "79848c35"
   },
   "outputs": [],
   "source": [
    "output = output.set_index('id')\n",
    "# output.to_csv('Submissions/submission28.csv')\n",
    "output.to_csv('submission34.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cecf7c5",
   "metadata": {
    "id": "8cecf7c5",
    "outputId": "2f32ea56-8067-496c-d069-1d33e25b35e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_pred > 100).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e191654",
   "metadata": {
    "id": "6e191654"
   },
   "source": [
    "## Clustering Ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1bece3",
   "metadata": {
    "id": "ed1bece3",
    "outputId": "dbddc9ca-98f6-4afc-8eee-1b374b51bd2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4118\n",
       "8     542\n",
       "6     332\n",
       "3     207\n",
       "5      95\n",
       "1      46\n",
       "4      22\n",
       "9      13\n",
       "2       3\n",
       "7       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "clusters = KMeans(random_state=0, n_clusters = 10)\n",
    "clusters.fit(data)\n",
    "\n",
    "pred = clusters.predict(data)\n",
    "data['Cluster'] = pred\n",
    "\n",
    "pd.Series(pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab23dae",
   "metadata": {
    "id": "dab23dae",
    "outputId": "0b667d2e-2d4c-4fea-ea40-9cf5b4704158"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x001</th>\n",
       "      <th>x002</th>\n",
       "      <th>x003</th>\n",
       "      <th>x004</th>\n",
       "      <th>x005</th>\n",
       "      <th>x006</th>\n",
       "      <th>x007</th>\n",
       "      <th>x008</th>\n",
       "      <th>x009</th>\n",
       "      <th>...</th>\n",
       "      <th>x758</th>\n",
       "      <th>x759</th>\n",
       "      <th>x760</th>\n",
       "      <th>x761</th>\n",
       "      <th>x762</th>\n",
       "      <th>x763</th>\n",
       "      <th>x764</th>\n",
       "      <th>x765</th>\n",
       "      <th>y</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.681860e+10</td>\n",
       "      <td>6991.15</td>\n",
       "      <td>7.76</td>\n",
       "      <td>0.00380</td>\n",
       "      <td>5.378811e+09</td>\n",
       "      <td>0.31</td>\n",
       "      <td>266117.20</td>\n",
       "      <td>934577.0</td>\n",
       "      <td>14539.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.972810e+08</td>\n",
       "      <td>0.13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.5127</td>\n",
       "      <td>14.28</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.304810e+09</td>\n",
       "      <td>13914.43</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0.00015</td>\n",
       "      <td>1.652405e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11927742.92</td>\n",
       "      <td>1798051.0</td>\n",
       "      <td>1051272.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.320000e+12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>661.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>1.5700</td>\n",
       "      <td>160.12</td>\n",
       "      <td>0.947097</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.218944e+10</td>\n",
       "      <td>3991.98</td>\n",
       "      <td>5.77</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>2.476111e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>774385.01</td>\n",
       "      <td>375738.0</td>\n",
       "      <td>144143.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004748e+08</td>\n",
       "      <td>0.39</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.6800</td>\n",
       "      <td>25.06</td>\n",
       "      <td>-0.490000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.288000e+10</td>\n",
       "      <td>15937.45</td>\n",
       "      <td>5.86</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>2.146667e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6324375.16</td>\n",
       "      <td>1932094.0</td>\n",
       "      <td>10055.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.480000e+11</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5316</td>\n",
       "      <td>117.76</td>\n",
       "      <td>1.640000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.063412e+10</td>\n",
       "      <td>3621.00</td>\n",
       "      <td>7.52</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>1.392460e+09</td>\n",
       "      <td>0.21</td>\n",
       "      <td>169860.29</td>\n",
       "      <td>474253.0</td>\n",
       "      <td>17914.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.095466e+08</td>\n",
       "      <td>0.11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.2717</td>\n",
       "      <td>5.81</td>\n",
       "      <td>-0.420000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5375</th>\n",
       "      <td>5375.0</td>\n",
       "      <td>3.948791e+09</td>\n",
       "      <td>24563.46</td>\n",
       "      <td>6.73</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>9.871977e+08</td>\n",
       "      <td>0.43</td>\n",
       "      <td>3303184.55</td>\n",
       "      <td>3154159.0</td>\n",
       "      <td>4439.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.586033e+08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7480</td>\n",
       "      <td>93.45</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5376</th>\n",
       "      <td>5376.0</td>\n",
       "      <td>9.279017e+10</td>\n",
       "      <td>21572.94</td>\n",
       "      <td>6.96</td>\n",
       "      <td>0.00120</td>\n",
       "      <td>3.093006e+09</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2649164.57</td>\n",
       "      <td>2934417.0</td>\n",
       "      <td>19106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.608917e+07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.6890</td>\n",
       "      <td>76.05</td>\n",
       "      <td>-0.900000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5377</th>\n",
       "      <td>5377.0</td>\n",
       "      <td>2.700359e+10</td>\n",
       "      <td>23061.73</td>\n",
       "      <td>6.36</td>\n",
       "      <td>0.00065</td>\n",
       "      <td>3.857656e+09</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1825306.07</td>\n",
       "      <td>2395841.0</td>\n",
       "      <td>71514.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.786891e+06</td>\n",
       "      <td>0.53</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.3710</td>\n",
       "      <td>80.30</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td>5378.0</td>\n",
       "      <td>4.351107e+10</td>\n",
       "      <td>5739.04</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.00065</td>\n",
       "      <td>1.318517e+09</td>\n",
       "      <td>0.29</td>\n",
       "      <td>144103.12</td>\n",
       "      <td>715173.0</td>\n",
       "      <td>13977.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.940000e+11</td>\n",
       "      <td>0.29</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.6594</td>\n",
       "      <td>7.95</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5379</th>\n",
       "      <td>5379.0</td>\n",
       "      <td>3.972951e+09</td>\n",
       "      <td>3368.55</td>\n",
       "      <td>6.15</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.324317e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>471263.24</td>\n",
       "      <td>419675.0</td>\n",
       "      <td>1457.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.740000e+12</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0195</td>\n",
       "      <td>19.07</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5380 rows Ã— 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id          x001      x002  x003     x004          x005  x006  \\\n",
       "0        0.0  9.681860e+10   6991.15  7.76  0.00380  5.378811e+09  0.31   \n",
       "1        1.0  3.304810e+09  13914.43  5.37  0.00015  1.652405e+09  0.00   \n",
       "2        2.0  3.218944e+10   3991.98  5.77  0.00010  2.476111e+09  0.00   \n",
       "3        3.0  1.288000e+10  15937.45  5.86  0.00020  2.146667e+09  0.00   \n",
       "4        4.0  3.063412e+10   3621.00  7.52  0.00060  1.392460e+09  0.21   \n",
       "...      ...           ...       ...   ...      ...           ...   ...   \n",
       "5375  5375.0  3.948791e+09  24563.46  6.73  0.00035  9.871977e+08  0.43   \n",
       "5376  5376.0  9.279017e+10  21572.94  6.96  0.00120  3.093006e+09  0.30   \n",
       "5377  5377.0  2.700359e+10  23061.73  6.36  0.00065  3.857656e+09  0.35   \n",
       "5378  5378.0  4.351107e+10   5739.04  7.80  0.00065  1.318517e+09  0.29   \n",
       "5379  5379.0  3.972951e+09   3368.55  6.15  0.00000  1.324317e+09  0.00   \n",
       "\n",
       "             x007       x008       x009  ...          x758  x759   x760  x761  \\\n",
       "0       266117.20   934577.0    14539.0  ...  2.972810e+08  0.13    5.0   5.0   \n",
       "1     11927742.92  1798051.0  1051272.0  ...  3.320000e+12  0.08  661.0   0.0   \n",
       "2       774385.01   375738.0   144143.0  ...  1.004748e+08  0.39   39.0   2.0   \n",
       "3      6324375.16  1932094.0    10055.0  ...  3.480000e+11  0.25    2.0   1.0   \n",
       "4       169860.29   474253.0    17914.0  ...  1.095466e+08  0.11   11.0   1.0   \n",
       "...           ...        ...        ...  ...           ...   ...    ...   ...   \n",
       "5375   3303184.55  3154159.0     4439.0  ...  1.586033e+08  0.05    0.0   0.0   \n",
       "5376   2649164.57  2934417.0    19106.0  ...  3.608917e+07  0.01    6.0   4.0   \n",
       "5377   1825306.07  2395841.0    71514.0  ...  1.786891e+06  0.53   44.0   0.0   \n",
       "5378    144103.12   715173.0    13977.0  ...  1.940000e+11  0.29    3.0   2.0   \n",
       "5379    471263.24   419675.0     1457.0  ...  5.740000e+12  0.51    0.0   0.0   \n",
       "\n",
       "       x762     x763    x764      x765     y  Cluster  \n",
       "0       2.0   8.5127   14.28 -0.750000   5.0        6  \n",
       "1     350.0   1.5700  160.12  0.947097   1.0        0  \n",
       "2      18.0   9.6800   25.06 -0.490000  11.0        0  \n",
       "3       0.0   4.5316  117.76  1.640000   1.0        0  \n",
       "4       3.0  16.2717    5.81 -0.420000   5.0        0  \n",
       "...     ...      ...     ...       ...   ...      ...  \n",
       "5375    0.0   2.7480   93.45  0.220000   4.0        0  \n",
       "5376    4.0  23.6890   76.05 -0.900000   8.0        0  \n",
       "5377   28.0   4.3710   80.30 -0.700000  21.0        0  \n",
       "5378    2.0  24.6594    7.95  0.470000  13.0        0  \n",
       "5379    0.0   2.0195   19.07  0.190000  28.0        0  \n",
       "\n",
       "[5380 rows x 768 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eaecdb",
   "metadata": {
    "id": "e6eaecdb",
    "outputId": "d49144ac-2524-46b6-ecdc-9a957aa64d60"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x001</th>\n",
       "      <th>x002</th>\n",
       "      <th>x003</th>\n",
       "      <th>x004</th>\n",
       "      <th>x005</th>\n",
       "      <th>x006</th>\n",
       "      <th>x007</th>\n",
       "      <th>x008</th>\n",
       "      <th>x009</th>\n",
       "      <th>...</th>\n",
       "      <th>x758</th>\n",
       "      <th>x759</th>\n",
       "      <th>x760</th>\n",
       "      <th>x761</th>\n",
       "      <th>x762</th>\n",
       "      <th>x763</th>\n",
       "      <th>x764</th>\n",
       "      <th>x765</th>\n",
       "      <th>y</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.681860e+10</td>\n",
       "      <td>6991.15</td>\n",
       "      <td>7.76</td>\n",
       "      <td>0.00380</td>\n",
       "      <td>5.378811e+09</td>\n",
       "      <td>0.31</td>\n",
       "      <td>266117.20</td>\n",
       "      <td>934577.0</td>\n",
       "      <td>14539.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.972810e+08</td>\n",
       "      <td>0.13</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.5127</td>\n",
       "      <td>14.28</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.304810e+09</td>\n",
       "      <td>13914.43</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0.00015</td>\n",
       "      <td>1.652405e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11927742.92</td>\n",
       "      <td>1798051.0</td>\n",
       "      <td>1051272.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.320000e+12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>661.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>1.5700</td>\n",
       "      <td>160.12</td>\n",
       "      <td>0.947097</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.218944e+10</td>\n",
       "      <td>3991.98</td>\n",
       "      <td>5.77</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>2.476111e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>774385.01</td>\n",
       "      <td>375738.0</td>\n",
       "      <td>144143.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004748e+08</td>\n",
       "      <td>0.39</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.6800</td>\n",
       "      <td>25.06</td>\n",
       "      <td>-0.490000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.288000e+10</td>\n",
       "      <td>15937.45</td>\n",
       "      <td>5.86</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>2.146667e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6324375.16</td>\n",
       "      <td>1932094.0</td>\n",
       "      <td>10055.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.480000e+11</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5316</td>\n",
       "      <td>117.76</td>\n",
       "      <td>1.640000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.063412e+10</td>\n",
       "      <td>3621.00</td>\n",
       "      <td>7.52</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>1.392460e+09</td>\n",
       "      <td>0.21</td>\n",
       "      <td>169860.29</td>\n",
       "      <td>474253.0</td>\n",
       "      <td>17914.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.095466e+08</td>\n",
       "      <td>0.11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.2717</td>\n",
       "      <td>5.81</td>\n",
       "      <td>-0.420000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5375</th>\n",
       "      <td>5375.0</td>\n",
       "      <td>3.948791e+09</td>\n",
       "      <td>24563.46</td>\n",
       "      <td>6.73</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>9.871977e+08</td>\n",
       "      <td>0.43</td>\n",
       "      <td>3303184.55</td>\n",
       "      <td>3154159.0</td>\n",
       "      <td>4439.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.586033e+08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7480</td>\n",
       "      <td>93.45</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5376</th>\n",
       "      <td>5376.0</td>\n",
       "      <td>9.279017e+10</td>\n",
       "      <td>21572.94</td>\n",
       "      <td>6.96</td>\n",
       "      <td>0.00120</td>\n",
       "      <td>3.093006e+09</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2649164.57</td>\n",
       "      <td>2934417.0</td>\n",
       "      <td>19106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.608917e+07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.6890</td>\n",
       "      <td>76.05</td>\n",
       "      <td>-0.900000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5377</th>\n",
       "      <td>5377.0</td>\n",
       "      <td>2.700359e+10</td>\n",
       "      <td>23061.73</td>\n",
       "      <td>6.36</td>\n",
       "      <td>0.00065</td>\n",
       "      <td>3.857656e+09</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1825306.07</td>\n",
       "      <td>2395841.0</td>\n",
       "      <td>71514.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.786891e+06</td>\n",
       "      <td>0.53</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.3710</td>\n",
       "      <td>80.30</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378</th>\n",
       "      <td>5378.0</td>\n",
       "      <td>4.351107e+10</td>\n",
       "      <td>5739.04</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.00065</td>\n",
       "      <td>1.318517e+09</td>\n",
       "      <td>0.29</td>\n",
       "      <td>144103.12</td>\n",
       "      <td>715173.0</td>\n",
       "      <td>13977.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.940000e+11</td>\n",
       "      <td>0.29</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.6594</td>\n",
       "      <td>7.95</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5379</th>\n",
       "      <td>5379.0</td>\n",
       "      <td>3.972951e+09</td>\n",
       "      <td>3368.55</td>\n",
       "      <td>6.15</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.324317e+09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>471263.24</td>\n",
       "      <td>419675.0</td>\n",
       "      <td>1457.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.740000e+12</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0195</td>\n",
       "      <td>19.07</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5380 rows Ã— 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id          x001      x002  x003     x004          x005  x006  \\\n",
       "0        0.0  9.681860e+10   6991.15  7.76  0.00380  5.378811e+09  0.31   \n",
       "1        1.0  3.304810e+09  13914.43  5.37  0.00015  1.652405e+09  0.00   \n",
       "2        2.0  3.218944e+10   3991.98  5.77  0.00010  2.476111e+09  0.00   \n",
       "3        3.0  1.288000e+10  15937.45  5.86  0.00020  2.146667e+09  0.00   \n",
       "4        4.0  3.063412e+10   3621.00  7.52  0.00060  1.392460e+09  0.21   \n",
       "...      ...           ...       ...   ...      ...           ...   ...   \n",
       "5375  5375.0  3.948791e+09  24563.46  6.73  0.00035  9.871977e+08  0.43   \n",
       "5376  5376.0  9.279017e+10  21572.94  6.96  0.00120  3.093006e+09  0.30   \n",
       "5377  5377.0  2.700359e+10  23061.73  6.36  0.00065  3.857656e+09  0.35   \n",
       "5378  5378.0  4.351107e+10   5739.04  7.80  0.00065  1.318517e+09  0.29   \n",
       "5379  5379.0  3.972951e+09   3368.55  6.15  0.00000  1.324317e+09  0.00   \n",
       "\n",
       "             x007       x008       x009  ...          x758  x759   x760  x761  \\\n",
       "0       266117.20   934577.0    14539.0  ...  2.972810e+08  0.13    5.0   5.0   \n",
       "1     11927742.92  1798051.0  1051272.0  ...  3.320000e+12  0.08  661.0   0.0   \n",
       "2       774385.01   375738.0   144143.0  ...  1.004748e+08  0.39   39.0   2.0   \n",
       "3      6324375.16  1932094.0    10055.0  ...  3.480000e+11  0.25    2.0   1.0   \n",
       "4       169860.29   474253.0    17914.0  ...  1.095466e+08  0.11   11.0   1.0   \n",
       "...           ...        ...        ...  ...           ...   ...    ...   ...   \n",
       "5375   3303184.55  3154159.0     4439.0  ...  1.586033e+08  0.05    0.0   0.0   \n",
       "5376   2649164.57  2934417.0    19106.0  ...  3.608917e+07  0.01    6.0   4.0   \n",
       "5377   1825306.07  2395841.0    71514.0  ...  1.786891e+06  0.53   44.0   0.0   \n",
       "5378    144103.12   715173.0    13977.0  ...  1.940000e+11  0.29    3.0   2.0   \n",
       "5379    471263.24   419675.0     1457.0  ...  5.740000e+12  0.51    0.0   0.0   \n",
       "\n",
       "       x762     x763    x764      x765     y  Cluster  \n",
       "0       2.0   8.5127   14.28 -0.750000   5.0        6  \n",
       "1     350.0   1.5700  160.12  0.947097   1.0        0  \n",
       "2      18.0   9.6800   25.06 -0.490000  11.0        0  \n",
       "3       0.0   4.5316  117.76  1.640000   1.0        0  \n",
       "4       3.0  16.2717    5.81 -0.420000   5.0        0  \n",
       "...     ...      ...     ...       ...   ...      ...  \n",
       "5375    0.0   2.7480   93.45  0.220000   4.0        0  \n",
       "5376    4.0  23.6890   76.05 -0.900000   8.0        0  \n",
       "5377   28.0   4.3710   80.30 -0.700000  21.0        0  \n",
       "5378    2.0  24.6594    7.95  0.470000  13.0        0  \n",
       "5379    0.0   2.0195   19.07  0.190000  28.0        0  \n",
       "\n",
       "[5380 rows x 768 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More general clusters?\n",
    "# DBSCAN?\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e543f468",
   "metadata": {
    "id": "e543f468",
    "outputId": "1c208850-e4eb-4a80-a9c3-4e3560ce7f10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dc6c2c",
   "metadata": {
    "id": "45dc6c2c"
   },
   "outputs": [],
   "source": [
    "X.to_csv('updated_X_train.csv')\n",
    "y.to_csv('logy.csv')\n",
    "data.to_csv('updated_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8546c0",
   "metadata": {
    "id": "ce8546c0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
